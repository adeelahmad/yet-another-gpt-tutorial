{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93746e6a",
   "metadata": {},
   "source": [
    "### Fine-tune GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14623c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI package version:0.28.0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import openai\n",
    "import time, random\n",
    "from datasets import load_dataset\n",
    "print (\"OpenAI package version:%s\"%(openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bfab77",
   "metadata": {},
   "source": [
    "### Load data from Hugging Face Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63000fd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e206acf69c4bc699dba6170c1761f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/1.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bf4335e3544a9e827df571750b2b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a40cb1bdd5cb4c859d45bf68639476e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/97.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830e2936d8be497eb398fa94cc524460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/4.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef337e9334514277935a77c271c10e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1686d37986f642e2a18e28b691ab31f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "581726e2b05d424592e39f81e21e16ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(path=\"AlekseyKorshuk/persona-chat\",name=\"persona-chat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0af8ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>personality</th>\n",
       "      <th>utterances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[i like to remodel homes ., i like to go hunti...</td>\n",
       "      <td>[{'candidates': ['my mom was single with 3 boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[my mom is my best friend ., i have four siste...</td>\n",
       "      <td>[{'candidates': ['there was one person better ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i had a gig at local theater last night ., i ...</td>\n",
       "      <td>[{'candidates': ['fine how are you feeling ton...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[i'm very athletic ., i wear contacts ., i hav...</td>\n",
       "      <td>[{'candidates': ['cool , i'm currently studyin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[i am primarily a meat eater ., i am a guitar ...</td>\n",
       "      <td>[{'candidates': ['yes , i like the green bay p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17873</th>\n",
       "      <td>[i sell miscellaneous stuff in local fairs ., ...</td>\n",
       "      <td>[{'candidates': ['interesting , luis is your g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17874</th>\n",
       "      <td>[i currently work at mcdonalds ., i live with ...</td>\n",
       "      <td>[{'candidates': ['her initials are c . c .', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>[i've a daughter ., i'm under 6 feet tall ., i...</td>\n",
       "      <td>[{'candidates': ['ya . but not as unwelcomed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>[i have a severe phobia of wide open spaces .,...</td>\n",
       "      <td>[{'candidates': ['i like to be smart . i'm ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>[my mother lives with me ., i like to plant fl...</td>\n",
       "      <td>[{'candidates': ['aprons , pot holders , table...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17878 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             personality  \\\n",
       "0      [i like to remodel homes ., i like to go hunti...   \n",
       "1      [my mom is my best friend ., i have four siste...   \n",
       "2      [i had a gig at local theater last night ., i ...   \n",
       "3      [i'm very athletic ., i wear contacts ., i hav...   \n",
       "4      [i am primarily a meat eater ., i am a guitar ...   \n",
       "...                                                  ...   \n",
       "17873  [i sell miscellaneous stuff in local fairs ., ...   \n",
       "17874  [i currently work at mcdonalds ., i live with ...   \n",
       "17875  [i've a daughter ., i'm under 6 feet tall ., i...   \n",
       "17876  [i have a severe phobia of wide open spaces .,...   \n",
       "17877  [my mother lives with me ., i like to plant fl...   \n",
       "\n",
       "                                              utterances  \n",
       "0      [{'candidates': ['my mom was single with 3 boy...  \n",
       "1      [{'candidates': ['there was one person better ...  \n",
       "2      [{'candidates': ['fine how are you feeling ton...  \n",
       "3      [{'candidates': ['cool , i'm currently studyin...  \n",
       "4      [{'candidates': ['yes , i like the green bay p...  \n",
       "...                                                  ...  \n",
       "17873  [{'candidates': ['interesting , luis is your g...  \n",
       "17874  [{'candidates': ['her initials are c . c .', '...  \n",
       "17875  [{'candidates': ['ya . but not as unwelcomed a...  \n",
       "17876  [{'candidates': ['i like to be smart . i'm ver...  \n",
       "17877  [{'candidates': ['aprons , pot holders , table...  \n",
       "\n",
       "[17878 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68c648f",
   "metadata": {},
   "source": [
    "### Since the nunber of training set is too small, we'll use test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "942e4bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TRAIN      = 1000\n",
    "NUM_VALIDATION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420d6dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_text = \"\"\"\n",
    "You are a interactive agent that follows the given persona:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfd8814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[../data/persona_chat_train.json1] saved.\n",
      "[../data/persona_chat_validation.json1] saved.\n"
     ]
    }
   ],
   "source": [
    "train_jsonl_path = '../data/persona_chat_train.json1'\n",
    "validation_jsonl_path  = '../data/persona_chat_validation.json1'\n",
    "with open(train_jsonl_path, 'w') as f:\n",
    "    for i in range(NUM_TRAIN):\n",
    "        data = dataset['train'][i]\n",
    "        persona =  \" \".join(data['personality'])\n",
    "        history = data['utterances'][-1]['history']\n",
    "        message = [{\"role\": \"system\", \"content\": persona}]\n",
    "        for i, h in enumerate(history):\n",
    "            if (i%2 == 0):\n",
    "                role = \"user\"\n",
    "            else: role = \"assistant\"\n",
    "            message.append({\"role\": role, \"content\": h})\n",
    "        line = {\"messages\": message}\n",
    "        # line = {\"messages\": [{\"role\": \"system\", \"content\": persona}, \n",
    "        #             {\"role\": \"user\", \"content\": \"Question: \" + data['question']},\n",
    "        #             {\"role\": \"assistant\", \"content\": \"Answer: \" + data['answer']}]}\n",
    "        f.write(json.dumps(line) + '\\n')\n",
    "\n",
    "with open(validation_jsonl_path, 'w') as f:\n",
    "    for i in range(NUM_TRAIN,NUM_TRAIN+NUM_VALIDATION):\n",
    "        data = dataset['train'][i]\n",
    "        persona =  \" \".join(data['personality'])\n",
    "        history = data['utterances'][-1]['history']\n",
    "        message = [{\"role\": \"system\", \"content\": persona}]\n",
    "        for i, h in enumerate(history):\n",
    "            if (i%2 == 0):\n",
    "                role = \"user\"\n",
    "            else: role = \"assistant\"\n",
    "            message.append({\"role\": role, \"content\": h})\n",
    "        line = {\"messages\": message}\n",
    "        f.write(json.dumps(line) + '\\n')\n",
    "print (\"[%s] saved.\"%(train_jsonl_path))\n",
    "print (\"[%s] saved.\"%(validation_jsonl_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618d724",
   "metadata": {},
   "source": [
    "### Locate the key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1787eb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = '../key/rilab_key.txt'\n",
    "print ('key_path:[%s]'%(key_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6ec80ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(key_path, 'r') as f: OPENAI_API_KEY = f.read()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0421cbb4",
   "metadata": {},
   "source": [
    "### Delete existing files (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "916d899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-HW2ySBmxZGxbkavqN5CwFTgD\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 137019,\n",
      "  \"created_at\": 1694411483,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-rEaiBrRYmva7r571MumUT7xv\",\n",
      "  \"purpose\": \"fine-tune-results\",\n",
      "  \"filename\": \"step_metrics.csv\",\n",
      "  \"bytes\": 17983,\n",
      "  \"created_at\": 1694413646,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-0Wrj9UoWNcXGAFjrSmqPeCpA\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 1364436,\n",
      "  \"created_at\": 1694411480,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "past_file_lists = openai.File.list()\n",
    "for past_file in past_file_lists['data']:\n",
    "    print (past_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6682978",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-0Wrj9UoWNcXGAFjrSmqPeCpA\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 1364436,\n",
      "  \"created_at\": 1694411480,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-HW2ySBmxZGxbkavqN5CwFTgD\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 137019,\n",
      "  \"created_at\": 1694411483,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-rEaiBrRYmva7r571MumUT7xv\",\n",
      "  \"purpose\": \"fine-tune-results\",\n",
      "  \"filename\": \"step_metrics.csv\",\n",
      "  \"bytes\": 17983,\n",
      "  \"created_at\": 1694413646,\n",
      "  \"status\": \"processed\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "past_file_lists = openai.File.list()\n",
    "for past_file in past_file_lists['data']:\n",
    "    idx = past_file['id']\n",
    "    if past_file['status'] == 'processed':\n",
    "        print (past_file)\n",
    "        openai.File.delete(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "580286dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print after deleting files\n",
    "past_file_lists = openai.File.list()\n",
    "for past_file in past_file_lists['data']:\n",
    "    print (past_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828eba6e",
   "metadata": {},
   "source": [
    "### Upload the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a11e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_train_data = openai.File.create(\n",
    "  file=open(train_jsonl_path, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_train_data_id = file_train_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2feb4c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test_data = openai.File.create(\n",
    "  file=open(validation_jsonl_path, \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")\n",
    "file_test_data_id = file_test_data.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f5f09d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-fh77pphFD9aiezuGPntLPRxm\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 1364436,\n",
      "  \"created_at\": 1694523224,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n",
      "{\n",
      "  \"object\": \"file\",\n",
      "  \"id\": \"file-LNhNveOLUVZEdbhwLJKXe7u8\",\n",
      "  \"purpose\": \"fine-tune\",\n",
      "  \"filename\": \"file\",\n",
      "  \"bytes\": 137019,\n",
      "  \"created_at\": 1694523225,\n",
      "  \"status\": \"uploaded\",\n",
      "  \"status_details\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print after deleting files\n",
    "past_file_lists = openai.File.list()\n",
    "for past_file in past_file_lists['data']:\n",
    "    print (past_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3245a02",
   "metadata": {},
   "source": [
    "### Wait for your data to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e6f78d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 uploaded\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 uploaded\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 uploaded\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 uploaded\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "1 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "0 file-fh77pphFD9aiezuGPntLPRxm uploaded\n",
      "1 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "0 file-LNhNveOLUVZEdbhwLJKXe7u8 processed\n",
      "1 file-fh77pphFD9aiezuGPntLPRxm processed\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    files = openai.File.list()\n",
    "    completed = True\n",
    "    for f_idx,file in enumerate(files['data']):\n",
    "        print(f_idx,file['id'], file['status'])\n",
    "        if file['id'] == file_train_data_id or file['id'] == file_test_data_id:\n",
    "            processed = (file['status'] == 'processed')\n",
    "            completed = completed and processed\n",
    "    if completed:\n",
    "        break\n",
    "    time.sleep(10)\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c969c0",
   "metadata": {},
   "source": [
    "### Cancel running models (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9c2849e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-xTZABRXWvpiYHl4TAjBWz29L succeeded\n",
      "ftjob-TxmbAGAFPoNgDwGdNr9kM7FJ succeeded\n",
      "ftjob-o3N7MRwfHtLXgvyheaO7pEHr succeeded\n",
      "ftjob-FyMhJGWK7LaGlu94NuAadINS cancelled\n",
      "ftjob-QcdcVVyLjBabDRhESarNTCpm succeeded\n",
      "ftjob-fhipvS2c2q7G3t4s7CLQGgDH succeeded\n",
      "ftjob-gNALz0Stw06p7e0NeI0isSAO succeeded\n",
      "ftjob-DAZc9L3aEKg1mNY2zFmpgdhv succeeded\n"
     ]
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "jobs = openai.FineTuningJob.list(limit=10)\n",
    "jobs = jobs['data']\n",
    "for job in jobs:\n",
    "    print(job['id'], job['status'])\n",
    "    job_id = job['id']\n",
    "    completed = job['status'] != 'running'\n",
    "    if not completed:\n",
    "        # Cancel a job\n",
    "        openai.FineTuningJob.cancel(job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86fa038",
   "metadata": {},
   "source": [
    "### Start fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06054afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "current_job = openai.FineTuningJob.create(\n",
    "    training_file=file_train_data_id, model=\"gpt-3.5-turbo\",\n",
    "    validation_file=file_test_data_id, hyperparameters={\"n_epochs\":1, })\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c30f4475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject list at 0x28e382220> JSON: {\n",
       "  \"object\": \"list\",\n",
       "  \"data\": [\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-8jBQV5vc2pmpUifBuRHhr8OY\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1694523358,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"running\",\n",
       "      \"validation_file\": \"file-LNhNveOLUVZEdbhwLJKXe7u8\",\n",
       "      \"training_file\": \"file-fh77pphFD9aiezuGPntLPRxm\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-xTZABRXWvpiYHl4TAjBWz29L\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1694411586,\n",
       "      \"finished_at\": 1694413644,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7xUgH1aA\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-rEaiBrRYmva7r571MumUT7xv\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-HW2ySBmxZGxbkavqN5CwFTgD\",\n",
       "      \"training_file\": \"file-0Wrj9UoWNcXGAFjrSmqPeCpA\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 246559,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-TxmbAGAFPoNgDwGdNr9kM7FJ\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693554274,\n",
       "      \"finished_at\": 1693554742,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7ttF0Dx2\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-ByRYue7nbUBQm4eYSZk2HhWI\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-t4PDvppb0D5qHrU4tHrfumh1\",\n",
       "      \"training_file\": \"file-rtZF3Ru65feoLs3eutQJsJ0H\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 831,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-o3N7MRwfHtLXgvyheaO7pEHr\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693548543,\n",
       "      \"finished_at\": 1693549009,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7trkYzgO\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-KQDYaX1BlnGQZHhk94Qjy35K\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-LTE83jTd01XEUQ6aiL1iLeuN\",\n",
       "      \"training_file\": \"file-a3z1jd3Kt5giIVLsxPubxGUH\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 831,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-FyMhJGWK7LaGlu94NuAadINS\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693548511,\n",
       "      \"finished_at\": null,\n",
       "      \"fine_tuned_model\": null,\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [],\n",
       "      \"status\": \"cancelled\",\n",
       "      \"validation_file\": \"file-LTE83jTd01XEUQ6aiL1iLeuN\",\n",
       "      \"training_file\": \"file-a3z1jd3Kt5giIVLsxPubxGUH\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": null,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-QcdcVVyLjBabDRhESarNTCpm\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693546893,\n",
       "      \"finished_at\": 1693547399,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7trKamW3\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-l5WBArbeZ1DKW79pm2USfrCn\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-Q5fBGxgptSjSWfvd2pdizTQ4\",\n",
       "      \"training_file\": \"file-3VlDNqS78TwXgLdi92igEz7B\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 914,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-fhipvS2c2q7G3t4s7CLQGgDH\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693545051,\n",
       "      \"finished_at\": 1693545516,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7tqqDVxu\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-WuxpCaSYmkq171yJVWGAGmbR\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-B2h4oSFYdJkA7zzE82nqft0h\",\n",
       "      \"training_file\": \"file-SXe3jQvUsMOrYS9GtfKR1g8s\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 914,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-gNALz0Stw06p7e0NeI0isSAO\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693544099,\n",
       "      \"finished_at\": 1693544596,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7tqbNGH5\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-GFZY2SmNEuwnRLXq2CmbCHJP\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": \"file-UEQLpqMsDH2Y7rJLCtbWnqY2\",\n",
       "      \"training_file\": \"file-abntl1qJwH7fVHfRXAn97hKR\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 1\n",
       "      },\n",
       "      \"trained_tokens\": 2551,\n",
       "      \"error\": null\n",
       "    },\n",
       "    {\n",
       "      \"object\": \"fine_tuning.job\",\n",
       "      \"id\": \"ftjob-DAZc9L3aEKg1mNY2zFmpgdhv\",\n",
       "      \"model\": \"gpt-3.5-turbo-0613\",\n",
       "      \"created_at\": 1693542580,\n",
       "      \"finished_at\": 1693543162,\n",
       "      \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:korea-university::7tqEGsAP\",\n",
       "      \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "      \"result_files\": [\n",
       "        \"file-IG5qEkSebmuqpDR3Zl5ljMA3\"\n",
       "      ],\n",
       "      \"status\": \"succeeded\",\n",
       "      \"validation_file\": null,\n",
       "      \"training_file\": \"file-szdPvDiHgfSoSMJKMsNCtGLG\",\n",
       "      \"hyperparameters\": {\n",
       "        \"n_epochs\": 3\n",
       "      },\n",
       "      \"trained_tokens\": 7653,\n",
       "      \"error\": null\n",
       "    }\n",
       "  ],\n",
       "  \"has_more\": false\n",
       "}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List 10 fine-tuning jobs\n",
    "openai.FineTuningJob.list(limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26012f7",
   "metadata": {},
   "source": [
    "### Retrieve information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "445ce90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_job_id:[ftjob-8jBQV5vc2pmpUifBuRHhr8OY]\n"
     ]
    }
   ],
   "source": [
    "current_job_id = current_job['id']\n",
    "print  (\"current_job_id:[%s]\"%(current_job_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72bc304c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<FineTuningJob fine_tuning.job id=ftjob-8jBQV5vc2pmpUifBuRHhr8OY at 0x28e388220> JSON: {\n",
       "  \"object\": \"fine_tuning.job\",\n",
       "  \"id\": \"ftjob-8jBQV5vc2pmpUifBuRHhr8OY\",\n",
       "  \"model\": \"gpt-3.5-turbo-0613\",\n",
       "  \"created_at\": 1694523358,\n",
       "  \"finished_at\": null,\n",
       "  \"fine_tuned_model\": null,\n",
       "  \"organization_id\": \"org-bT1bA6ExTcdQphsyv85F0j6z\",\n",
       "  \"result_files\": [],\n",
       "  \"status\": \"running\",\n",
       "  \"validation_file\": \"file-LNhNveOLUVZEdbhwLJKXe7u8\",\n",
       "  \"training_file\": \"file-fh77pphFD9aiezuGPntLPRxm\",\n",
       "  \"hyperparameters\": {\n",
       "    \"n_epochs\": 1\n",
       "  },\n",
       "  \"trained_tokens\": null,\n",
       "  \"error\": null\n",
       "}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the state of a fine-tune\n",
    "openai.FineTuningJob.retrieve(current_job_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2f8800",
   "metadata": {},
   "source": [
    "### Wait for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "704937f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Fine tuning job started\n",
      "Created fine-tuning job: ftjob-8jBQV5vc2pmpUifBuRHhr8OY\n",
      "Step 100/1000: training loss=1.76\n",
      "Fine tuning job started\n",
      "Step 100/1000: training loss=1.76\n",
      "Fine tuning job started\n",
      "Step 100/1000: training loss=1.76\n",
      "Fine tuning job started\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 100/1000: training loss=1.76\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 100/1000: training loss=1.76\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 100/1000: training loss=1.76\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 200/1000: training loss=1.96\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 300/1000: training loss=1.85\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 400/1000: training loss=2.87\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 500/1000: training loss=2.48\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 600/1000: training loss=1.93\n",
      "Step 800/1000: training loss=1.89\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 800/1000: training loss=1.89\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 800/1000: training loss=1.89\n",
      "Step 700/1000: training loss=2.23\n",
      "Step 900/1000: training loss=1.53\n",
      "Step 800/1000: training loss=1.89\n",
      "Step 900/1000: training loss=1.53\n",
      "Step 800/1000: training loss=1.89\n",
      "Step 900/1000: training loss=1.53\n",
      "Step 800/1000: training loss=1.89\n",
      "The job has successfully completed\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:korea-university::7xxqUPHt\n",
      "=====================================\n",
      "The job has successfully completed\n",
      "{}\n",
      "=====================================\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0613:korea-university::7xxqUPHt\n",
      "{}\n",
      "=====================================\n",
      "Step 1000/1000: training loss=1.82\n",
      "{\n",
      "  \"step\": 1000,\n",
      "  \"train_loss\": 1.82290518283844,\n",
      "  \"train_mean_token_accuracy\": 0.5504587292671204\n",
      "}\n",
      "=====================================\n",
      "Step 900/1000: training loss=1.53\n",
      "{\n",
      "  \"step\": 900,\n",
      "  \"train_loss\": 1.5286750793457031,\n",
      "  \"train_mean_token_accuracy\": 0.625\n",
      "}\n",
      "=====================================\n",
      "Step 800/1000: training loss=1.89\n",
      "{\n",
      "  \"step\": 800,\n",
      "  \"train_loss\": 1.8901692628860474,\n",
      "  \"train_mean_token_accuracy\": 0.5660377144813538\n",
      "}\n",
      "=====================================\n",
      "Step 700/1000: training loss=2.23\n",
      "{\n",
      "  \"step\": 700,\n",
      "  \"train_loss\": 2.2319793701171875,\n",
      "  \"train_mean_token_accuracy\": 0.47058823704719543\n",
      "}\n",
      "=====================================\n",
      "Step 600/1000: training loss=1.93\n",
      "{\n",
      "  \"step\": 600,\n",
      "  \"train_loss\": 1.9274938106536865,\n",
      "  \"train_mean_token_accuracy\": 0.5145630836486816\n",
      "}\n",
      "=====================================\n",
      "Step 500/1000: training loss=2.48\n",
      "{\n",
      "  \"step\": 500,\n",
      "  \"train_loss\": 2.4816272258758545,\n",
      "  \"train_mean_token_accuracy\": 0.4084506928920746\n",
      "}\n",
      "=====================================\n",
      "Step 400/1000: training loss=2.87\n",
      "{\n",
      "  \"step\": 400,\n",
      "  \"train_loss\": 2.870401620864868,\n",
      "  \"train_mean_token_accuracy\": 0.4650000035762787\n",
      "}\n",
      "=====================================\n",
      "Step 300/1000: training loss=1.85\n",
      "{\n",
      "  \"step\": 300,\n",
      "  \"train_loss\": 1.846813440322876,\n",
      "  \"train_mean_token_accuracy\": 0.529411792755127\n",
      "}\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    job = openai.FineTuningJob.retrieve(current_job_id)\n",
    "    completed = job['status'] != 'running'\n",
    "    # List up to 10 events from a fine-tuning job\n",
    "    events = openai.FineTuningJob.list_events(id=current_job_id, limit=2)\n",
    "    for event in events['data']:\n",
    "        print(event['message'])\n",
    "    if completed:\n",
    "        break\n",
    "    time.sleep(60)\n",
    "events = openai.FineTuningJob.list_events(id=current_job_id, limit=10)\n",
    "for event in events['data']:\n",
    "    print(\"=====================================\")\n",
    "    print(event['message'])\n",
    "    print(event['data'])\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685011a6",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66be38d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = openai.FineTuningJob.retrieve(current_job_id)['fine_tuned_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca0074b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'personality': ['although i m studying to be a doctor , animals like me .', \"i'm a graduate student .\", 'i volunteer with dogs .', 'i am in between classes .', 'i m always early .'], 'utterances': [{'candidates': ['just a small pet cat . you have cats ?', 'i do like a lot of none gmo types of food', 'same , thinking of ordering a pizza . wish i could get sushi !', 'general office supplies , what do you do ?', 'i love books by stephen king', 'hello how is your sunday ?', 'that is so sweet ! is she sick ?', 'i walk around the mall when i have a chance .', \"i don't care for his books .\", 'i am , thank you . tell me about your personality .', 'why do you not date ?', 'hello mate , how are you today', 'i do not really watch many . i mostly spend time reading', 'good morning , how are you ?', 'what instrument do you play ?', 'do you happen to have a daughter named dorothy ?', \"ll , i'm already hungry enough . at this point , my lizards look edible .\", 'how about just 1 friend ?', 'wow you sound like a healthy person', \"hey i don't have long to chat . how are you ?\"], 'history': ['__ SILENCE __']}, {'candidates': ['hello , how is your weekend going ?', 'is that what you do on youtube ?', 'i am doing good . i am just drinking my favorite coffee right now .', 'i am alone . what about you ?', 'yes i like that since i work in a book store', 'hi , how are you today ?', \"i love dogs but don't have any pets\", 'oh , i just work odd jobs here and there', 'nice to meet you . i like to live a more enlightened life i guess', 'yeah , no joke . i love golden retrievers . i might get one of my own soon', 'it was the only thing that got me through the chemo for my wife', 'where are you from ? i am in cali', \"i'll only live for a few more months\", 'hi how are you doing', 'i prefer ice cream or frozen yogurt .', 'you like them or are you not that close ?', 'it gets better . have you thought of joining the army ?', \"my name is sam , and i've an addiction to high stakes blackjack\", 'i like comic books . i love superhero ones .', 'what are you up to today ?'], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .']}, {'candidates': ['yes i did . i hope to find a job when i graduate next september', 'i have heard of it . never played though . busy with guitar , haha .', 'love country music . went shopping today and bought a new bmw', \"i'm on a diet so i try to watch what i eat\", 'nah , i cycle at night . its hard to hike at night .', 'you sure can ! i met him in a cave during halloween last year', 'i am pretty shy , so this is a big deal for me . i do like to sing though', 'nice to meet you ! i am don and i love being outside . do you work ?', 'that is a great job , i just work at an office in my city', 'i only drink coke from china , and it is hard to find in the usa', 'yeah the aliens are quiet creatures .', \"sure , i've settled down a little bit too . but i still love concerts !\", 'where do you rap at', 'what is up my man ?', 'about her life as i can remember it , she passed on when i was 9', \"haha i'm a kid ! i'm in third grade and love soccer ! you ?\", 'bread , we are the bread family haha , teaching is awesome', 'i have a few kittens', 'it certainly sounds that way', 'nice ! you should take pictures of shelter dogs and help them get adopted !'], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\"]}, {'candidates': ['do you have a favorite color ?', 'bicycles must be so useful there ? except in winter . or maybe not ?', 'i like any brand that good will carries .', 'what kind of sea food do you like', 'it helps when you have a deadbeat for a father . i fend for myself .', \"i've three they are the best\", 'i love apples . macintosh are the best !', 'noone opinion matters but yours . i love roses', 'not really . i like to stay home a lot but i might go out to eat .', 'oh and i also have these chronically bad back pains', 'i love having my back scratched , and making candles .', 'hello from pittsburgh where i live', \"don't blame you . must be cold in buffalo .\", 'i am in college for childhood', 'i read the walking dead comics and watch the show', 'besides that i like okra , peas , apples and bananas best', 'nice , sounds like a delicious job', 'yes . we are all here for a reason', 'cults suck , when was the last time you heard from her', \"me too . animals like me and i like them . i'm in medical school though\"], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\", 'nice ! you should take pictures of shelter dogs and help them get adopted !', \"that's a good idea . i love animals .\"]}, {'candidates': ['i have absolutely no energy ! i stay home with the kids . but i am a serious cleaner', 'that is fine . if we can make them explode .', 'do you enjoy to read ? i could read while you fish ?', 'i have almost finished with it too ! just gotta finish one book .', \"no , i don't . what did you have for breakfast today ?\", 'working all day , my feet hurt and smell , but money is my favorite thing i love it', 'i am going for medical billing not to bad .', 'i like bambi you just made me cry', 'he retires next year . luckily , i am already retired . i live on the west coast . you ?', 'hi . tell me about you .', 'second year how long in the dress design business', 'my bf watches twitch a lot .', 'family pictures ! family is everything to me ! how big is yours ?', 'ugh , i am sorry . do you have any hobbies ?', \"i've rex , pepper and miko\", 'i like to go for a run when i wake up it really energizes me', \"hello ! i'm well , thanks ! how are you ?\", 'thank you . i try to be a positive influence in this world .', \"i don't do music , i listen to it .\", \"i'm waiting for class to start . i get here too quick but there's no real time\"], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\", 'nice ! you should take pictures of shelter dogs and help them get adopted !', \"that's a good idea . i love animals .\", \"me too . animals like me and i like them . i'm in medical school though\", \"that's very admirable too . i've taken photos of doctors in action before .\"]}, {'candidates': ['yeah , it is sad . i should just hang out and listen to music .', \"that is a fun sport i do rock climbing when i'm able\", 'haha , its my favorite subject . when i graduate i wanna go to college for it !', \"that's awesome , man . i am still in the closet and i am so conflicted . . .\", 'lol well i manage a grocery store , talk about boring', 'i have a degree in communication , and i am in the navy .', 'fun ! do you mystery novels ?', 'i think my favorite is hamburger !', 'my son is awesome straight as', 'i like bands vnv is the one i like alot .', \"yeah , i've been seeing this girl for a few months .\", \"ow i haven't ridden a horse in a long time . i have to take certain medications\", \"my two children they're for under 10\", 'all about drawing comics . i like them a lot', 'no kidding ? ! before i was in law school , i skied outside chicago .', 'i used to drive my mother crazy , i liked to smoke , i am tee total now though', 'lol gotcha . . . this is michael', '6 years ago when i was in highschool', 'yes actually . a cat named majora .', 'for sure . i volunteer with the shelter in my spare time .'], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\", 'nice ! you should take pictures of shelter dogs and help them get adopted !', \"that's a good idea . i love animals .\", \"me too . animals like me and i like them . i'm in medical school though\", \"that's very admirable too . i've taken photos of doctors in action before .\", \"i'm waiting for class to start . i get here too quick but there's no real time\", 'i do that too . got to get the best seat .']}, {'candidates': ['an honor ! but i also have 2 siberians . those huskies are like a second job !', 'i am a vet at the animal shelter', 'glad you are studying english . it must be difficult learning english and living in a new culture .', 'meet your parents ? ! my hair is still red from the accident !', 'i went shopping online and got a purse', \"yes i'm the leader of a band and the leader at my local gun club\", 'i love dogs ! my mutt loves swimming in our lake .', 'we need to get a pianist . would help me stay on key', 'do you have any pets ? i love dogs', 'hi ! do you like dogs ?', \"that is cool . well i've to get back to my studies soon . is there anything else ?\", 'that is kind of you to say but are you funny also ?', 'that is the best thing ever', 'hello ! what do you do ?', 'yes i can make any color simple or bold look', 'what is his name , if i may ask ?', 'i am not stressed i just want to look fabulous forever lol', \"you love photography that's a great hobby for traveling\", 'yea , i like cars but i needed a truck for the farm , so i changed', 'what is wrong with her'], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\", 'nice ! you should take pictures of shelter dogs and help them get adopted !', \"that's a good idea . i love animals .\", \"me too . animals like me and i like them . i'm in medical school though\", \"that's very admirable too . i've taken photos of doctors in action before .\", \"i'm waiting for class to start . i get here too quick but there's no real time\", 'i do that too . got to get the best seat .', 'for sure . i volunteer with the shelter in my spare time .', 'my wife used to help out at the shelter before she got sick .']}, {'candidates': ['full house here too . i have 6 brothers and sisters , we were all adopted', \"well , i would like to , but i don't have time for it .\", \"i'm am doing good do u like sports\", 'i play a few instruments ! i really want to be able to paly music for a living', 'i disagree , i love my small town', 'hello , how are you today ?', 'my dad does tax assesment and my mom teaches !', 'can i come then please', 'are you looking for any kind of design advice by any chance ?', 'i am doing well thank you . just been working on a short film myself .', 'i just learned to read . we can be friends and i will read about trains .', 'awesome ! they sleeping . luckily i brought my fav book . the tale of genji .', 'hello how are you today', 'ok when did you become deaf', 'hi how are you dong ?', 'i think people think i m lazy because i still live at home with mom . what about you ?', 'i think magic mike is a movie i like a lot , uh , because of the music .', 'i just work on my wood work and make couches and stuff', 'yes . i miss my wife and kids . are you married ?', \"sorry to hear that . that's sad .\"], 'history': ['__ SILENCE __', \"hey i don't have long to chat . how are you ?\", 'that s ok i don t have long either . i m fine .', 'what are you up to today ?', \"i'm taking pictures . i'm a photographer\", 'nice ! you should take pictures of shelter dogs and help them get adopted !', \"that's a good idea . i love animals .\", \"me too . animals like me and i like them . i'm in medical school though\", \"that's very admirable too . i've taken photos of doctors in action before .\", \"i'm waiting for class to start . i get here too quick but there's no real time\", 'i do that too . got to get the best seat .', 'for sure . i volunteer with the shelter in my spare time .', 'my wife used to help out at the shelter before she got sick .', 'what is wrong with her', 'she had cancer . she passed away .']}]}\n"
     ]
    }
   ],
   "source": [
    "start_idx = NUM_TRAIN + NUM_VALIDATION\n",
    "end_idx = len(dataset['train'])\n",
    "sample_idx = random.randint(start_idx, end_idx)\n",
    "sample = dataset['train'][sample_idx]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a6a0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona =  \" \".join(sample['personality'])\n",
    "history = sample['utterances'][-1]['history']\n",
    "messages =  [\n",
    "    {\"role\": \"system\", \"content\": persona},\n",
    "    {\"role\": \"user\", \"content\": history[0]},\n",
    "    {\"role\": \"assistant\", \"content\": history[1]},\n",
    "    {\"role\": \"user\", \"content\": history[2]},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b748321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion = openai.ChatCompletion.create(\n",
    "  model=model_id,\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0bf97bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: although i m studying to be a doctor , animals like me . i'm a graduate student . i volunteer with dogs . i am in between classes . i m always early .\n",
      "user: __ SILENCE __\n",
      "assistant: hey i don't have long to chat . how are you ?\n",
      "user: that s ok i don t have long either . i m fine .\n",
      "response: what do you do for work ? i am getting ready to be a doctor\n",
      "Ground Truth: what are you up to today ?\n"
     ]
    }
   ],
   "source": [
    "answer = response['choices'][0]['message']['content']\n",
    "print('Persona: ' + persona)\n",
    "print('user: ' + history[0])\n",
    "print('assistant: ' + history[1])\n",
    "print('user: ' + history[2])\n",
    "print('response: ' + answer)\n",
    "print('Ground Truth: ' + history[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4e00d67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persona =  \"I am an extroverted person \"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": persona},\n",
    "    {\"role\": \"user\", \"content\": \"If you see someone waving their hand what will you do?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f4755da",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = completion = openai.ChatCompletion.create(\n",
    "  model=model_id,\n",
    "  messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decf8785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: I am an extroverted person \n",
      "response: I wave my hands to when I talk as I am an extroverted person\n"
     ]
    }
   ],
   "source": [
    "answer = response['choices'][0]['message']['content']\n",
    "print('Persona: ' + persona)\n",
    "print('response: ' + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f602646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Persona: I am an extroverted person \n",
      "response: As an extroverted person, I would likely feel comfortable and excited to engage with them. I would wave back, approach them, and start a friendly conversation.\n"
     ]
    }
   ],
   "source": [
    "response = completion = openai.ChatCompletion.create(\n",
    "  model='gpt-4',\n",
    "  messages=messages\n",
    ")\n",
    "answer = response['choices'][0]['message']['content']\n",
    "print('Persona: ' + persona)\n",
    "print('response: ' + answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab198c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
