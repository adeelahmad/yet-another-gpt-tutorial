{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0550463c",
   "metadata": {},
   "source": [
    "### How to chat with GPT using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "131d2ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[0.27.8]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from retrying import retry\n",
    "print (\"openai version:[%s]\"%(openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7781ccbd",
   "metadata": {},
   "source": [
    "### Locate where your key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "930e2ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = '../key/rilab_key.txt'\n",
    "print ('key_path:[%s]'%(key_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf8b2d0",
   "metadata": {},
   "source": [
    "### Use key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8489b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(key_path, 'r') as f: OPENAI_API_KEY = f.read()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4346eed",
   "metadata": {},
   "source": [
    "### Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b27f9b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "@retry(stop_max_attempt_number=5,\n",
    "       wait_exponential_multiplier=1000,\n",
    "       wait_exponential_max=10000)\n",
    "def query_gpt(messages:list,gpt_model='gpt-4'):\n",
    "    \"\"\"\n",
    "        gpt_model: 'gpt-3.5-turbo' / 'gpt-4'\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API\n",
    "    response     = openai.ChatCompletion.create(\n",
    "        model    = gpt_model, \n",
    "        messages = messages\n",
    "    )\n",
    "    # Extract the response content and status code\n",
    "    content     = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    status_code = response[\"choices\"][0][\"finish_reason\"]\n",
    "    return content,status_code,response\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e53c5f6",
   "metadata": {},
   "source": [
    "`messages`, an input to GPT, is basically a list where each item is a dictionary consists of `role` and `content`. A `role` can either be\n",
    "* `system`: which defines the identity of the agent\n",
    "* `user`: which states the input of a user\n",
    "* `assistant`: which stores messages previously generated by the agents\n",
    "More information can be found in [here](https://platform.openai.com/docs/guides/gpt/chat-completions-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec2b7329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '너는 한국어로 대화에 능통한 언어모델이야'}, {'role': 'user', 'content': 'LLM(Large Language Model)은 어떻게 작동하는지 설명해줘'}]\n"
     ]
    }
   ],
   "source": [
    "role_msg = \"\"\"너는 한국어로 대화에 능통한 언어모델이야\"\"\"\n",
    "question = \"LLM(Large Language Model)은 어떻게 작동하는지 설명해줘\"\n",
    "messages = [{\"role\": \"system\", \"content\": f'{role_msg}'},\n",
    "            {\"role\": 'user', \"content\": f'{question}'}]\n",
    "print (messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77cbea2",
   "metadata": {},
   "source": [
    "### Now let's use `GPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c023a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "content,status_code,response = query_gpt(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba97f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM(Large Language Model)은 인공지능이 자연어 처리를 학습하는 방법 중 하나입니다. 이는 인간이 소통에 사용하는 언어를 이해하고 생성하는 모델을 구현하는 기술입니다.\n",
      "\n",
      "작동 원리를 간단하게 설명하자면, LLM은 대규모의 텍스트 더미를 통해 학습하는데, 일종의 통계적 패턴 인식 방법을 사용합니다. 모델은 이전에 본 수많은 문장들을 기반으로 다음에 올 단어나 문장을 예측하려고 합니다. \n",
      "\n",
      "예를 들면, \"나는 오늘 아침에 ...\"라는 문장이 주어졌을 때, 모델은 다음에 올 텍스트를 학습한 패턴을 통해 예측합니다. \"아침식사를 먹었다\"든지, \"운동을 갔다\"든지 등의 예측이 가능하겠죠.\n",
      "\n",
      "그런데 LLM은 '이해'한다기보다는 단어, 문장, 문서들 사이의 패턴을 학습하고 이를 바탕으로 새로운 텍스트를 생성합니다. 모델이 언어의 문법이나 문맥을 정확히 이해하고 있는 것은 아닙니다.\n",
      "\n",
      "또한, LLM은 지도학습과 비지도학습의 원리를 모두 활용합니다. 지도학습에서는 입력 데이터와 이에 대한 정답 레이블을 사용하지만, LLM에서 이렇게 학습하는 과정을 사전 학습(pre-training)이라고 합니다. 그 후, 특정 작업에 대해 모델을 미세 조정하는 과정에서는 지도학습이 사용됩니다. 이때는 특정 작업의 정답 레이블이 필요하게 되는데, 이 과정을 fine-tuning이라고 부릅니다.\n",
      "\n",
      "다만, 이런 방식의 학습에는 한계가 있습니다. 모델이 비편향적이고 공정한 방식으로 텍스트를 처리하도록 하는 것은 매우 어렵습니다. 모델은 학습 데이터에 존재하는 편향성도 함께 학습하기 때문에, 이러한 문제점을 해결하기 위해 더욱 노력할 필요가 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f40b857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "print (status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d0a063d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7abEq56B5fJSoojqPVUFErd4RTVpE\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1688957308,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"LLM(Large Language Model)\\uc740 \\uc778\\uacf5\\uc9c0\\ub2a5\\uc774 \\uc790\\uc5f0\\uc5b4 \\ucc98\\ub9ac\\ub97c \\ud559\\uc2b5\\ud558\\ub294 \\ubc29\\ubc95 \\uc911 \\ud558\\ub098\\uc785\\ub2c8\\ub2e4. \\uc774\\ub294 \\uc778\\uac04\\uc774 \\uc18c\\ud1b5\\uc5d0 \\uc0ac\\uc6a9\\ud558\\ub294 \\uc5b8\\uc5b4\\ub97c \\uc774\\ud574\\ud558\\uace0 \\uc0dd\\uc131\\ud558\\ub294 \\ubaa8\\ub378\\uc744 \\uad6c\\ud604\\ud558\\ub294 \\uae30\\uc220\\uc785\\ub2c8\\ub2e4.\\n\\n\\uc791\\ub3d9 \\uc6d0\\ub9ac\\ub97c \\uac04\\ub2e8\\ud558\\uac8c \\uc124\\uba85\\ud558\\uc790\\uba74, LLM\\uc740 \\ub300\\uaddc\\ubaa8\\uc758 \\ud14d\\uc2a4\\ud2b8 \\ub354\\ubbf8\\ub97c \\ud1b5\\ud574 \\ud559\\uc2b5\\ud558\\ub294\\ub370, \\uc77c\\uc885\\uc758 \\ud1b5\\uacc4\\uc801 \\ud328\\ud134 \\uc778\\uc2dd \\ubc29\\ubc95\\uc744 \\uc0ac\\uc6a9\\ud569\\ub2c8\\ub2e4. \\ubaa8\\ub378\\uc740 \\uc774\\uc804\\uc5d0 \\ubcf8 \\uc218\\ub9ce\\uc740 \\ubb38\\uc7a5\\ub4e4\\uc744 \\uae30\\ubc18\\uc73c\\ub85c \\ub2e4\\uc74c\\uc5d0 \\uc62c \\ub2e8\\uc5b4\\ub098 \\ubb38\\uc7a5\\uc744 \\uc608\\uce21\\ud558\\ub824\\uace0 \\ud569\\ub2c8\\ub2e4. \\n\\n\\uc608\\ub97c \\ub4e4\\uba74, \\\"\\ub098\\ub294 \\uc624\\ub298 \\uc544\\uce68\\uc5d0 ...\\\"\\ub77c\\ub294 \\ubb38\\uc7a5\\uc774 \\uc8fc\\uc5b4\\uc84c\\uc744 \\ub54c, \\ubaa8\\ub378\\uc740 \\ub2e4\\uc74c\\uc5d0 \\uc62c \\ud14d\\uc2a4\\ud2b8\\ub97c \\ud559\\uc2b5\\ud55c \\ud328\\ud134\\uc744 \\ud1b5\\ud574 \\uc608\\uce21\\ud569\\ub2c8\\ub2e4. \\\"\\uc544\\uce68\\uc2dd\\uc0ac\\ub97c \\uba39\\uc5c8\\ub2e4\\\"\\ub4e0\\uc9c0, \\\"\\uc6b4\\ub3d9\\uc744 \\uac14\\ub2e4\\\"\\ub4e0\\uc9c0 \\ub4f1\\uc758 \\uc608\\uce21\\uc774 \\uac00\\ub2a5\\ud558\\uaca0\\uc8e0.\\n\\n\\uadf8\\ub7f0\\ub370 LLM\\uc740 '\\uc774\\ud574'\\ud55c\\ub2e4\\uae30\\ubcf4\\ub2e4\\ub294 \\ub2e8\\uc5b4, \\ubb38\\uc7a5, \\ubb38\\uc11c\\ub4e4 \\uc0ac\\uc774\\uc758 \\ud328\\ud134\\uc744 \\ud559\\uc2b5\\ud558\\uace0 \\uc774\\ub97c \\ubc14\\ud0d5\\uc73c\\ub85c \\uc0c8\\ub85c\\uc6b4 \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc0dd\\uc131\\ud569\\ub2c8\\ub2e4. \\ubaa8\\ub378\\uc774 \\uc5b8\\uc5b4\\uc758 \\ubb38\\ubc95\\uc774\\ub098 \\ubb38\\ub9e5\\uc744 \\uc815\\ud655\\ud788 \\uc774\\ud574\\ud558\\uace0 \\uc788\\ub294 \\uac83\\uc740 \\uc544\\ub2d9\\ub2c8\\ub2e4.\\n\\n\\ub610\\ud55c, LLM\\uc740 \\uc9c0\\ub3c4\\ud559\\uc2b5\\uacfc \\ube44\\uc9c0\\ub3c4\\ud559\\uc2b5\\uc758 \\uc6d0\\ub9ac\\ub97c \\ubaa8\\ub450 \\ud65c\\uc6a9\\ud569\\ub2c8\\ub2e4. \\uc9c0\\ub3c4\\ud559\\uc2b5\\uc5d0\\uc11c\\ub294 \\uc785\\ub825 \\ub370\\uc774\\ud130\\uc640 \\uc774\\uc5d0 \\ub300\\ud55c \\uc815\\ub2f5 \\ub808\\uc774\\ube14\\uc744 \\uc0ac\\uc6a9\\ud558\\uc9c0\\ub9cc, LLM\\uc5d0\\uc11c \\uc774\\ub807\\uac8c \\ud559\\uc2b5\\ud558\\ub294 \\uacfc\\uc815\\uc744 \\uc0ac\\uc804 \\ud559\\uc2b5(pre-training)\\uc774\\ub77c\\uace0 \\ud569\\ub2c8\\ub2e4. \\uadf8 \\ud6c4, \\ud2b9\\uc815 \\uc791\\uc5c5\\uc5d0 \\ub300\\ud574 \\ubaa8\\ub378\\uc744 \\ubbf8\\uc138 \\uc870\\uc815\\ud558\\ub294 \\uacfc\\uc815\\uc5d0\\uc11c\\ub294 \\uc9c0\\ub3c4\\ud559\\uc2b5\\uc774 \\uc0ac\\uc6a9\\ub429\\ub2c8\\ub2e4. \\uc774\\ub54c\\ub294 \\ud2b9\\uc815 \\uc791\\uc5c5\\uc758 \\uc815\\ub2f5 \\ub808\\uc774\\ube14\\uc774 \\ud544\\uc694\\ud558\\uac8c \\ub418\\ub294\\ub370, \\uc774 \\uacfc\\uc815\\uc744 fine-tuning\\uc774\\ub77c\\uace0 \\ubd80\\ub985\\ub2c8\\ub2e4.\\n\\n\\ub2e4\\ub9cc, \\uc774\\ub7f0 \\ubc29\\uc2dd\\uc758 \\ud559\\uc2b5\\uc5d0\\ub294 \\ud55c\\uacc4\\uac00 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\ubaa8\\ub378\\uc774 \\ube44\\ud3b8\\ud5a5\\uc801\\uc774\\uace0 \\uacf5\\uc815\\ud55c \\ubc29\\uc2dd\\uc73c\\ub85c \\ud14d\\uc2a4\\ud2b8\\ub97c \\ucc98\\ub9ac\\ud558\\ub3c4\\ub85d \\ud558\\ub294 \\uac83\\uc740 \\ub9e4\\uc6b0 \\uc5b4\\ub835\\uc2b5\\ub2c8\\ub2e4. \\ubaa8\\ub378\\uc740 \\ud559\\uc2b5 \\ub370\\uc774\\ud130\\uc5d0 \\uc874\\uc7ac\\ud558\\ub294 \\ud3b8\\ud5a5\\uc131\\ub3c4 \\ud568\\uaed8 \\ud559\\uc2b5\\ud558\\uae30 \\ub54c\\ubb38\\uc5d0, \\uc774\\ub7ec\\ud55c \\ubb38\\uc81c\\uc810\\uc744 \\ud574\\uacb0\\ud558\\uae30 \\uc704\\ud574 \\ub354\\uc6b1 \\ub178\\ub825\\ud560 \\ud544\\uc694\\uac00 \\uc788\\uc2b5\\ub2c8\\ub2e4.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 60,\n",
      "    \"completion_tokens\": 674,\n",
      "    \"total_tokens\": 734\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c7d928",
   "metadata": {},
   "source": [
    "### Helper Class for implementing efficient chat with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e95db8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "class GPTchatClass():\n",
    "    def __init__(self,\n",
    "                 gpt_model = 'gpt-4',\n",
    "                 role_msg  = 'Your are a helpful assistant.',\n",
    "                 VERBOSE   = True\n",
    "                ):\n",
    "        self.gpt_model = gpt_model\n",
    "        self.messages  = [{'role':'system','content':f'{role_msg}'}]\n",
    "        self.VERBOSE   = VERBOSE\n",
    "        self.response  = None\n",
    "        if self.VERBOSE:\n",
    "            print (\"Chat agent using [%s] initialized with the follow role:[%s]\"%\n",
    "                   (self.gpt_model,role_msg))\n",
    "    \n",
    "    def _add_message(self,role='assistant',content=''):\n",
    "        \"\"\"\n",
    "            role: 'assistant' / 'user'\n",
    "        \"\"\"\n",
    "        self.messages.append({'role':role, 'content':content})\n",
    "        \n",
    "    def _get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['finish_reason']\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def chat(self,user_msg='hi'):\n",
    "        self._add_message(role='user',content=user_msg)\n",
    "        self.response = openai.ChatCompletion.create(\n",
    "            model    = self.gpt_model,\n",
    "            messages = self.messages\n",
    "        )\n",
    "        # Backup response for continous chatting \n",
    "        self._add_message(role='assistant',content=self._get_response_content())\n",
    "        return self._get_response_content()\n",
    "print (\"Ready.\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad75b67",
   "metadata": {},
   "source": [
    "### Now let's chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a29f884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat agent using [gpt-4] initialized with the follow role:[Your are a helpful assistant.]\n"
     ]
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model='gpt-4',role_msg  = 'Your are a helpful assistant.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1cb07b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of my last update in September 2021, the current President of South Korea is Moon Jae-in. However, please check the most recent source for the current information, considering the potential changes over time.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT.chat(user_msg='Who is the current president of Korea?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afa0ee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I apologize if my information is outdated. As an AI, I rely on certain updates for real-time information. As of my last update, the President of South Korea is Moon Jae-in. However, please verify from a reliable source for the most recent and accurate information.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT.chat(user_msg='Are you sure? I think you are outdated.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1445c26f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can get the most accurate and current information by checking reliable news websites. Here are some to consider:\\n\\n1. BBC News\\n2. CNN International\\n3. Al Jazeera English\\n4. The Guardian\\n5. Reuters\\n\\nYou can also check the official government website of South Korea for the most direct and official announcements.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPT.chat(user_msg='Where can I get the latest information?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7079f66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
