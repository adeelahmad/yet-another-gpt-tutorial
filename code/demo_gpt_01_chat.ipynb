{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee5fb83",
   "metadata": {},
   "source": [
    "### How to chat with GPT using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0533bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[0.28.0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from retrying import retry\n",
    "from IPython.display import Markdown,display\n",
    "print (\"openai version:[%s]\"%(openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900baa7d",
   "metadata": {},
   "source": [
    "### Locate where your key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3b903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = '../key/rilab_key.txt'\n",
    "print ('key_path:[%s]'%(key_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b03f",
   "metadata": {},
   "source": [
    "### Use key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2fc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(key_path, 'r') as f: OPENAI_API_KEY = f.read()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd6db4",
   "metadata": {},
   "source": [
    "### Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830439b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "@retry(stop_max_attempt_number=5,\n",
    "       wait_exponential_multiplier=1000,\n",
    "       wait_exponential_max=10000)\n",
    "def query_gpt(messages:list,gpt_model='gpt-4'):\n",
    "    \"\"\"\n",
    "        gpt_model: 'gpt-3.5-turbo' / 'gpt-4'\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API\n",
    "    response     = openai.ChatCompletion.create(\n",
    "        model    = gpt_model, \n",
    "        messages = messages\n",
    "    )\n",
    "    # Extract the response content and status code\n",
    "    content     = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    status_code = response[\"choices\"][0][\"finish_reason\"]\n",
    "    return content,status_code,response\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48f062",
   "metadata": {},
   "source": [
    "`messages`, an input to GPT, is basically a list where each item is a dictionary consists of `role` and `content`. A `role` can either be\n",
    "* `system`: which defines the identity of the agent\n",
    "* `user`: which states the input of a user\n",
    "* `assistant`: which stores messages previously generated by the agents\n",
    "More information can be found in [here](https://platform.openai.com/docs/guides/gpt/chat-completions-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ab7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '너는 한국어로 대화에 능통한 언어모델이야'}, {'role': 'user', 'content': 'LLM(Large Language Model)은 어떻게 작동하는지 설명해줘'}]\n"
     ]
    }
   ],
   "source": [
    "role_msg = \"\"\"너는 한국어로 대화에 능통한 언어모델이야\"\"\"\n",
    "question = \"LLM(Large Language Model)은 어떻게 작동하는지 설명해줘\"\n",
    "messages = [{\"role\": \"system\", \"content\": f'{role_msg}'},\n",
    "            {\"role\": 'user', \"content\": f'{question}'}]\n",
    "print (messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f4f53",
   "metadata": {},
   "source": [
    "### Now let's use `GPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccc1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "content,status_code,response = query_gpt(messages=messages,gpt_model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74676205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM은 큰 규모의 언어 모델로, 텍스트 관련 작업을 수행하기 위해 사용됩니다. LLM은 기계 학습 기술을 사용하여 훈련되며, 많은 양의 텍스트 데이터를 이용해 언어의 통계적 패턴과 구조를 학습합니다.\n",
      "\n",
      "LLM은 주어진 입력에 대한 다음 단어나 문장을 예측하는 데 사용됩니다. 예를 들어, \"나는 오늘\"이라는 입력이 주어진다면, LLM은 다음에 올 수 있는 가능한 단어를 예측하여 \"나는 오늘 먹었다\" 또는 \"나는 오늘 공부했다\"와 같은 결과를 출력할 수 있습니다.\n",
      "\n",
      "LLM은 작동하기 위해 큰 양의 데이터를 사용합니다. 대규모의 코퍼스(텍스트 데이터 모음)를 사용하여 많은 문장과 문서를 학습하고, 문법, 단어 간의 관계, 의미, 문맥 등 다양한 언어적 특징을 학습합니다.\n",
      "\n",
      "LLM은 훈련된 이후에는 실제 응용 프로그램에서 다양한 작업에 활용될 수 있습니다. 예를 들어, 기계 번역, 자동 요약, 질의응답 시스템, 텍스트 생성 등에 활용될 수 있습니다. LLM은 입력 텍스트와 관련된 문제에 대한 올바른 예측을 생성하여 도움을 줄 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d330b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "print (status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9daf9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8FRQqdZgJ0nN2kSmQKIeiekX9Gx8c\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698691060,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"LLM\\uc740 \\ud070 \\uaddc\\ubaa8\\uc758 \\uc5b8\\uc5b4 \\ubaa8\\ub378\\ub85c, \\ud14d\\uc2a4\\ud2b8 \\uad00\\ub828 \\uc791\\uc5c5\\uc744 \\uc218\\ud589\\ud558\\uae30 \\uc704\\ud574 \\uc0ac\\uc6a9\\ub429\\ub2c8\\ub2e4. LLM\\uc740 \\uae30\\uacc4 \\ud559\\uc2b5 \\uae30\\uc220\\uc744 \\uc0ac\\uc6a9\\ud558\\uc5ec \\ud6c8\\ub828\\ub418\\uba70, \\ub9ce\\uc740 \\uc591\\uc758 \\ud14d\\uc2a4\\ud2b8 \\ub370\\uc774\\ud130\\ub97c \\uc774\\uc6a9\\ud574 \\uc5b8\\uc5b4\\uc758 \\ud1b5\\uacc4\\uc801 \\ud328\\ud134\\uacfc \\uad6c\\uc870\\ub97c \\ud559\\uc2b5\\ud569\\ub2c8\\ub2e4.\\n\\nLLM\\uc740 \\uc8fc\\uc5b4\\uc9c4 \\uc785\\ub825\\uc5d0 \\ub300\\ud55c \\ub2e4\\uc74c \\ub2e8\\uc5b4\\ub098 \\ubb38\\uc7a5\\uc744 \\uc608\\uce21\\ud558\\ub294 \\ub370 \\uc0ac\\uc6a9\\ub429\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uc5b4, \\\"\\ub098\\ub294 \\uc624\\ub298\\\"\\uc774\\ub77c\\ub294 \\uc785\\ub825\\uc774 \\uc8fc\\uc5b4\\uc9c4\\ub2e4\\uba74, LLM\\uc740 \\ub2e4\\uc74c\\uc5d0 \\uc62c \\uc218 \\uc788\\ub294 \\uac00\\ub2a5\\ud55c \\ub2e8\\uc5b4\\ub97c \\uc608\\uce21\\ud558\\uc5ec \\\"\\ub098\\ub294 \\uc624\\ub298 \\uba39\\uc5c8\\ub2e4\\\" \\ub610\\ub294 \\\"\\ub098\\ub294 \\uc624\\ub298 \\uacf5\\ubd80\\ud588\\ub2e4\\\"\\uc640 \\uac19\\uc740 \\uacb0\\uacfc\\ub97c \\ucd9c\\ub825\\ud560 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\\n\\nLLM\\uc740 \\uc791\\ub3d9\\ud558\\uae30 \\uc704\\ud574 \\ud070 \\uc591\\uc758 \\ub370\\uc774\\ud130\\ub97c \\uc0ac\\uc6a9\\ud569\\ub2c8\\ub2e4. \\ub300\\uaddc\\ubaa8\\uc758 \\ucf54\\ud37c\\uc2a4(\\ud14d\\uc2a4\\ud2b8 \\ub370\\uc774\\ud130 \\ubaa8\\uc74c)\\ub97c \\uc0ac\\uc6a9\\ud558\\uc5ec \\ub9ce\\uc740 \\ubb38\\uc7a5\\uacfc \\ubb38\\uc11c\\ub97c \\ud559\\uc2b5\\ud558\\uace0, \\ubb38\\ubc95, \\ub2e8\\uc5b4 \\uac04\\uc758 \\uad00\\uacc4, \\uc758\\ubbf8, \\ubb38\\ub9e5 \\ub4f1 \\ub2e4\\uc591\\ud55c \\uc5b8\\uc5b4\\uc801 \\ud2b9\\uc9d5\\uc744 \\ud559\\uc2b5\\ud569\\ub2c8\\ub2e4.\\n\\nLLM\\uc740 \\ud6c8\\ub828\\ub41c \\uc774\\ud6c4\\uc5d0\\ub294 \\uc2e4\\uc81c \\uc751\\uc6a9 \\ud504\\ub85c\\uadf8\\ub7a8\\uc5d0\\uc11c \\ub2e4\\uc591\\ud55c \\uc791\\uc5c5\\uc5d0 \\ud65c\\uc6a9\\ub420 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4. \\uc608\\ub97c \\ub4e4\\uc5b4, \\uae30\\uacc4 \\ubc88\\uc5ed, \\uc790\\ub3d9 \\uc694\\uc57d, \\uc9c8\\uc758\\uc751\\ub2f5 \\uc2dc\\uc2a4\\ud15c, \\ud14d\\uc2a4\\ud2b8 \\uc0dd\\uc131 \\ub4f1\\uc5d0 \\ud65c\\uc6a9\\ub420 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4. LLM\\uc740 \\uc785\\ub825 \\ud14d\\uc2a4\\ud2b8\\uc640 \\uad00\\ub828\\ub41c \\ubb38\\uc81c\\uc5d0 \\ub300\\ud55c \\uc62c\\ubc14\\ub978 \\uc608\\uce21\\uc744 \\uc0dd\\uc131\\ud558\\uc5ec \\ub3c4\\uc6c0\\uc744 \\uc904 \\uc218 \\uc788\\uc2b5\\ub2c8\\ub2e4.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 60,\n",
      "    \"completion_tokens\": 440,\n",
      "    \"total_tokens\": 500\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddce3",
   "metadata": {},
   "source": [
    "### Helper Class for implementing efficient chat with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46db1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "class GPTchatClass():\n",
    "    def __init__(self,\n",
    "                 gpt_model = 'gpt-4',\n",
    "                 role_msg  = 'Your are a helpful assistant.',\n",
    "                 VERBOSE   = True\n",
    "                ):\n",
    "        self.gpt_model     = gpt_model\n",
    "        self.messages      = [{'role':'system','content':f'{role_msg}'}]\n",
    "        self.init_messages = [{'role':'system','content':f'{role_msg}'}]\n",
    "        self.VERBOSE       = VERBOSE\n",
    "        self.response      = None\n",
    "        if self.VERBOSE:\n",
    "            print (\"Chat agent using [%s] initialized with the follow role:[%s]\"%\n",
    "                   (self.gpt_model,role_msg))\n",
    "    \n",
    "    def _add_message(self,role='assistant',content=''):\n",
    "        \"\"\"\n",
    "            role: 'assistant' / 'user'\n",
    "        \"\"\"\n",
    "        self.messages.append({'role':role, 'content':content})\n",
    "        \n",
    "    def _get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['finish_reason']\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def chat(self,user_msg='hi',\n",
    "             PRINT_USER_MSG=True,PRINT_GPT_OUTPUT=True,\n",
    "             RESET_CHAT=False,RETURN_RESPONSE=True):\n",
    "        self._add_message(role='user',content=user_msg)\n",
    "        self.response = openai.ChatCompletion.create(\n",
    "            model    = self.gpt_model,\n",
    "            messages = self.messages\n",
    "        )\n",
    "        # Backup response for continous chatting\n",
    "        self._add_message(role='assistant',content=self._get_response_content())\n",
    "        if PRINT_USER_MSG:\n",
    "            print(\"[USER_MSG]\")\n",
    "            printmd(user_msg)\n",
    "        if PRINT_GPT_OUTPUT:\n",
    "            print(\"[GPT_OUTPUT]\")\n",
    "            printmd(self._get_response_content())\n",
    "        # Reset\n",
    "        if RESET_CHAT:\n",
    "            self.messages = self.init_messages\n",
    "        # Return\n",
    "        if RETURN_RESPONSE:\n",
    "            return self._get_response_content()\n",
    "print (\"Ready.\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240f58b",
   "metadata": {},
   "source": [
    "### Now let's chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c6ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat agent using [gpt-3.5-turbo] initialized with the follow role:[Your are a helpful assistant.]\n",
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As of my last update in November 2021, the current president of South Korea is Moon Jae-in. However, please note that political positions can change, so it's always a good idea to verify with the latest information from reliable sources."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I apologize if my previous response was outdated. As an AI, I do not have real-time information updates. As of November 2021, Moon Jae-in was serving as the president of South Korea, but please verify with the latest sources to ensure accuracy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "For the most up-to-date and accurate information on the current president of South Korea, I recommend checking reliable news sources such as reputable news websites, government websites, or official government social media accounts. These sources usually provide the most recent and accurate information on political leadership and updates."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model='gpt-3.5-turbo',role_msg  = 'Your are a helpful assistant.')\n",
    "PRINT_USER_MSG   = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT       = False\n",
    "RETURN_RESPONSE  = False\n",
    "GPT.chat(user_msg='Who is the current president of Korea?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Are you sure? I think you are outdated.',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Where can I get the latest information?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3dff58",
   "metadata": {},
   "source": [
    "### Chat with resetting everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3982d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat agent using [gpt-3.5-turbo] initialized with the follow role:[Your are a helpful assistant.]\n",
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As of my knowledge, the current President of South Korea is Moon Jae-in."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm here to assist you to the best of my ability. While I may not have the latest information or be able to perform certain tasks, I'll do my best to help you with any questions or tasks you have. Let me know how I can assist you!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "To get the latest information, there are several reliable sources you can turn to:\n",
       "\n",
       "1. News websites: Popular news websites like BBC News, CNN, Reuters, or The New York Times provide up-to-date news on various topics.\n",
       "\n",
       "2. Social media platforms: Follow reputable news outlets or journalists on platforms like Twitter, where they often share the latest updates and breaking news.\n",
       "\n",
       "3. Official government websites: Government websites provide reliable information on topics such as public health, policies, and current events. Look for websites specific to your country or region.\n",
       "\n",
       "4. Trusted experts and organizations: Follow experts or organizations related to the topic you're interested in. For example, if you're looking for health-related information, following the World Health Organization (WHO) or the Centers for Disease Control and Prevention (CDC) can provide reliable updates.\n",
       "\n",
       "Remember, it's always important to verify the credibility of your sources and cross-reference information from multiple reliable sources to ensure accuracy."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model='gpt-3.5-turbo',role_msg  = 'Your are a helpful assistant.')\n",
    "PRINT_USER_MSG   = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT       = True\n",
    "RETURN_RESPONSE  = False\n",
    "GPT.chat(user_msg='Who is the current president of Korea?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Are you sure? I think you are outdated.',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Where can I get the latest information?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b54979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
