{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee5fb83",
   "metadata": {},
   "source": [
    "### How to chat with GPT using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0d0533bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[1.3.7]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from retrying import retry\n",
    "from rich.console import Console\n",
    "\n",
    "print(\"openai version:[%s]\" % (openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869e462",
   "metadata": {},
   "source": [
    "### Locate where your key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af4a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = \"../key/rilab_key.txt\"\n",
    "print(\"key_path:[%s]\" % (key_path))\n",
    "\n",
    "with open(key_path, \"r\") as f:\n",
    "    OPENAI_API_KEY = f.read()\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd6db4",
   "metadata": {},
   "source": [
    "### Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "830439b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def query_gpt(messages: list, gpt_model=\"gpt-4\"):\n",
    "    \"\"\"\n",
    "    gpt_model: 'gpt-3.5-turbo' / 'gpt-4'\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API\n",
    "    response = client.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    # Extract the response content and status code\n",
    "    content = response.choices[0].message.content\n",
    "    status_code = response.choices[0].finish_reason\n",
    "    return content, status_code, response\n",
    "\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48f062",
   "metadata": {},
   "source": [
    "`messages`, an input to GPT, is basically a list where each item is a dictionary consists of `role` and `content`. A `role` can either be\n",
    "* `system`: which defines the identity of the agent\n",
    "* `user`: which states the input of a user\n",
    "* `assistant`: which stores messages previously generated by the agents\n",
    "More information can be found in [here](https://platform.openai.com/docs/guides/gpt/chat-completions-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "84ab7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '너는 한국어로 대화에 능통한 언어모델이야'}, {'role': 'user', 'content': 'LLM(Large Language Model)은 어떻게 작동하는지 설명해줘'}]\n"
     ]
    }
   ],
   "source": [
    "role_msg = \"\"\"너는 한국어로 대화에 능통한 언어모델이야\"\"\"\n",
    "question = \"LLM(Large Language Model)은 어떻게 작동하는지 설명해줘\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{role_msg}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{question}\"},\n",
    "]\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f4f53",
   "metadata": {},
   "source": [
    "### Now let's use `GPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2ccc1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "content, status_code, response = query_gpt(messages=messages, gpt_model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "74676205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM(Large Language Model)은 기계 학습 기술을 사용하여 텍스트 데이터를 학습하고 생성하는 언어 모델입니다. LLM은 큰 양의 텍스트 데이터를 이용하여 문법, 문맥, 의미 등 언어의 다양한 측면을 학습하여 다양한 언어 작업을 수행할 수 있습니다.\n",
      "\n",
      "LLM은 대량의 텍스트 데이터셋, 예를 들면 인터넷에서 수집한 언어 샘플, 문서, 뉴스 기사, 도서, 논문 등을 사용하여 학습됩니다. 이런 데이터는 언어의 다양한 관점, 문체, 주제 등을 포함하고 있어 LLM이 다양한 상황에 대응하고 자연스러운 언어 생성을 할 수 있도록 돕습니다.\n",
      "\n",
      "LLM은 훈련 데이터의 통계적 패턴을 학습하고, 문장 구조, 단어 선택, 문맥 이해 등 다양한 언어적 특징을 파악합니다. 이를 통해 입력 문맥에 따라 다음에 올 단어나 문장을 예측하고 생성합니다. 예를 들어, \"나는 오늘 밥을\"까지 주어진 경우, LLM은 \"먹었어요\"나 \"먹으러 갈래요\"와 같은 다음 단어를 자연스럽게 예측할 수 있습니다.\n",
      "\n",
      "LLM은 학습한 언어 모델의 일부를 사용자에게 제공하여 대화를 지원합니다. 사용자 입력에 따라 LLM은 문맥과 의미를 이해하고 적합한 답변을 생성합니다. LLM은 이전에 본 적 없는 문장에도 일관된 문체와 의미를 유지하며 자연스럽게 응답할 수 있습니다.\n",
      "\n",
      "LLM의 작동 방식은 주어진 입력 문구와 해당 문구에 따른 추론과 생성 과정을 기반으로 합니다. 학습된 데이터의 통계적 패턴을 기반으로 LLM은 가능성이 높은 응답을 생성하고, 연습을 통해 보다 정확하고 유연한 응답을 구축합니다.\n",
      "\n",
      "그러나 LLM은 단어, 문장 생성 과정에서 완벽하지는 않을 수 있습니다. 때로는 문맥을 제대로 이해하지 못하거나 부적절한 응답을 생성하기도 합니다. 따라서 LLM은 사용자의 입력에 대해 신중하게 판단하고, 생성된 응답의 적절성을 확인하는 것이 중요합니다.\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d330b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "print(status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b9daf9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8SxS4HwfoOOrL5IyBf9AFsapE4lpy', choices=[Choice(finish_reason='stop', index=0, message=ChatCompletionMessage(content='LLM(Large Language Model)은 기계 학습 기술을 사용하여 텍스트 데이터를 학습하고 생성하는 언어 모델입니다. LLM은 큰 양의 텍스트 데이터를 이용하여 문법, 문맥, 의미 등 언어의 다양한 측면을 학습하여 다양한 언어 작업을 수행할 수 있습니다.\\n\\nLLM은 대량의 텍스트 데이터셋, 예를 들면 인터넷에서 수집한 언어 샘플, 문서, 뉴스 기사, 도서, 논문 등을 사용하여 학습됩니다. 이런 데이터는 언어의 다양한 관점, 문체, 주제 등을 포함하고 있어 LLM이 다양한 상황에 대응하고 자연스러운 언어 생성을 할 수 있도록 돕습니다.\\n\\nLLM은 훈련 데이터의 통계적 패턴을 학습하고, 문장 구조, 단어 선택, 문맥 이해 등 다양한 언어적 특징을 파악합니다. 이를 통해 입력 문맥에 따라 다음에 올 단어나 문장을 예측하고 생성합니다. 예를 들어, \"나는 오늘 밥을\"까지 주어진 경우, LLM은 \"먹었어요\"나 \"먹으러 갈래요\"와 같은 다음 단어를 자연스럽게 예측할 수 있습니다.\\n\\nLLM은 학습한 언어 모델의 일부를 사용자에게 제공하여 대화를 지원합니다. 사용자 입력에 따라 LLM은 문맥과 의미를 이해하고 적합한 답변을 생성합니다. LLM은 이전에 본 적 없는 문장에도 일관된 문체와 의미를 유지하며 자연스럽게 응답할 수 있습니다.\\n\\nLLM의 작동 방식은 주어진 입력 문구와 해당 문구에 따른 추론과 생성 과정을 기반으로 합니다. 학습된 데이터의 통계적 패턴을 기반으로 LLM은 가능성이 높은 응답을 생성하고, 연습을 통해 보다 정확하고 유연한 응답을 구축합니다.\\n\\n그러나 LLM은 단어, 문장 생성 과정에서 완벽하지는 않을 수 있습니다. 때로는 문맥을 제대로 이해하지 못하거나 부적절한 응답을 생성하기도 합니다. 따라서 LLM은 사용자의 입력에 대해 신중하게 판단하고, 생성된 응답의 적절성을 확인하는 것이 중요합니다.', role='assistant', function_call=None, tool_calls=None))], created=1701912408, model='gpt-3.5-turbo-0613', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=734, prompt_tokens=60, total_tokens=794))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddce3",
   "metadata": {},
   "source": [
    "### Helper Class for implementing efficient chat with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "46db1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "class GPTchatClass:\n",
    "    def __init__(\n",
    "        self,\n",
    "        gpt_model: str = \"gpt-4\",\n",
    "        role_msg: str = \"Your are a helpful assistant.\",\n",
    "        VERBOSE: str = True,\n",
    "    ):\n",
    "        self.gpt_model = gpt_model\n",
    "        self.messages = [{\"role\": \"system\", \"content\": f\"{role_msg}\"}]\n",
    "        self.init_messages = [{\"role\": \"system\", \"content\": f\"{role_msg}\"}]\n",
    "        self.VERBOSE = VERBOSE\n",
    "        if self.VERBOSE:\n",
    "            self.console = Console()\n",
    "        self.response = None\n",
    "\n",
    "        self._setup_client()\n",
    "\n",
    "    def _setup_client(self, key_path: str = \"../\"):\n",
    "        key_path = \"../key/rilab_key.txt\"\n",
    "        if self.VERBOSE:\n",
    "            self.console.print(f\"[bold cyan]key_path:[%s][/bold cyan]\" % (key_path))\n",
    "\n",
    "        with open(key_path, \"r\") as f:\n",
    "            OPENAI_API_KEY = f.read()\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        if self.VERBOSE:\n",
    "            self.console.print(\n",
    "                \"[bold cyan]Chat agent using [%s] initialized with the follow role:[%s][/bold cyan]\"\n",
    "                % (self.gpt_model, role_msg)\n",
    "            )\n",
    "\n",
    "    def _add_message(self, role=\"assistant\", content=\"\"):\n",
    "        \"\"\"\n",
    "        role: 'assistant' / 'user'\n",
    "        \"\"\"\n",
    "        self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def _get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response.choices[0].message.content\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response.choices[0].message.finish_reason\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def chat(\n",
    "        self,\n",
    "        user_msg=\"hi\",\n",
    "        PRINT_USER_MSG=True,\n",
    "        PRINT_GPT_OUTPUT=True,\n",
    "        RESET_CHAT=False,\n",
    "        RETURN_RESPONSE=True,\n",
    "    ):\n",
    "        self._add_message(role=\"user\", content=user_msg)\n",
    "        self.response = self.client.chat.completions.create(\n",
    "            model=self.gpt_model, messages=self.messages\n",
    "        )\n",
    "        # Backup response for continous chatting\n",
    "        self._add_message(role=\"assistant\", content=self._get_response_content())\n",
    "        if PRINT_USER_MSG:\n",
    "            self.console.print(\"[deep_sky_blue3][USER_MSG][/deep_sky_blue3]\")\n",
    "            printmd(user_msg)\n",
    "        if PRINT_GPT_OUTPUT:\n",
    "            self.console.print(\"[spring_green4][GPT_OUTPUT][/spring_green4]\")\n",
    "            printmd(self._get_response_content())\n",
    "        # Reset\n",
    "        if RESET_CHAT:\n",
    "            self.messages = self.init_messages\n",
    "        # Return\n",
    "        if RETURN_RESPONSE:\n",
    "            return self._get_response_content()\n",
    "\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240f58b",
   "metadata": {},
   "source": [
    "### Now let's chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "87c6ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">key_path:[../key/rilab_key.txt]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mkey_path:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m..\u001b[0m\u001b[1;36m/key/\u001b[0m\u001b[1;36mrilab_key.txt\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Chat agent using  initialized with the follow role:[너는 한국어로 대화에 능통한 언어모델이야]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mChat agent using \u001b[0m\u001b[1;36m initialized with the follow role:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m너는 한국어로 대화에 능통한 언어모델이야\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "As of September 2021, the current president of South Korea is Moon Jae-in."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "I apologize for any confusion caused. Please note that as an AI language model, my responses are based on information available up to September 2021. If there have been any recent changes in the political landscape, I may not be aware of them. To get the most up-to-date and accurate information, I recommend referring to reliable sources or news outlets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To get the latest and most accurate information, I recommend referring to reliable news sources and official government websites. Here are some reputable sources you can consider:\n",
       "\n",
       "1. News outlets such as CNN, BBC, Reuters, Al Jazeera, and The New York Times often provide up-to-date news coverage from around the world.\n",
       "2. Official government websites or press releases from institutions like the Office of the President or Ministry of Foreign Affairs of the country you are interested in can provide reliable information on political leaders and updates.\n",
       "3. Local news outlets in the specific country of interest can also provide relevant and current information.\n",
       "\n",
       "Remember to verify information from multiple sources to ensure accuracy and stay updated on any changes or developments."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model=\"gpt-3.5-turbo\", role_msg=\"Your are a helpful assistant.\")\n",
    "PRINT_USER_MSG = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT = False\n",
    "RETURN_RESPONSE = False\n",
    "GPT.chat(\n",
    "    user_msg=\"Who is the current president of Korea?\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")\n",
    "GPT.chat(\n",
    "    user_msg=\"Are you sure? I think you are outdated.\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")\n",
    "GPT.chat(\n",
    "    user_msg=\"Where can I get the latest information?\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3dff58",
   "metadata": {},
   "source": [
    "### Chat with resetting everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0b3982d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">key_path:[../key/rilab_key.txt]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mkey_path:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m..\u001b[0m\u001b[1;36m/key/\u001b[0m\u001b[1;36mrilab_key.txt\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Chat agent using  initialized with the follow role:[너는 한국어로 대화에 능통한 언어모델이야]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mChat agent using \u001b[0m\u001b[1;36m initialized with the follow role:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m너는 한국어로 대화에 능통한 언어모델이야\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "As of my last update in October 2021, the current president of South Korea is Moon Jae-in. Please note that political positions might change over time, so it's always a good idea to check for the most up-to-date information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "As an AI language model, I am constantly learning and adapting to provide up-to-date and relevant information. While I may not always have the most recent information on every topic, I strive to provide helpful and accurate assistance based on the data and knowledge available to me. If I am unable to assist with a specific question or topic, I will do my best to redirect you to other sources or suggest alternative approaches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "To get the latest information on a specific topic, there are several reliable sources you can turn to:\n",
       "\n",
       "1. News websites: Visit reputable news websites such as BBC News, CNN, Reuters, or The New York Times. These sources typically cover a wide range of current topics and provide reliable and up-to-date news articles.\n",
       "\n",
       "2. Official government websites: For information on government policies, regulations, or updates on various topics, visit official government websites related to your country or the subject you are interested in.\n",
       "\n",
       "3. Industry-specific websites: If you are looking for the latest information on a specific industry or field, check out websites dedicated to that industry. Many industries have specialized websites or news outlets that provide industry-specific updates and news.\n",
       "\n",
       "4. Social media platforms: Follow verified accounts on social media platforms like Twitter or Facebook relating to the areas you want to get the latest information from. Many organizations, journalists, and experts share real-time updates and news on these platforms.\n",
       "\n",
       "5. Online forums and communities: Engage in online forums or communities that focus on your area of interest. Often, members of these communities share and discuss the latest news and developments.\n",
       "\n",
       "Remember, it's always important to verify information from multiple sources, especially when dealing with fast-changing or controversial topics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model=\"gpt-3.5-turbo\", role_msg=\"Your are a helpful assistant.\")\n",
    "PRINT_USER_MSG = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT = True\n",
    "RETURN_RESPONSE = False\n",
    "GPT.chat(\n",
    "    user_msg=\"Who is the current president of Korea?\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")\n",
    "GPT.chat(\n",
    "    user_msg=\"Are you sure? I think you are outdated.\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")\n",
    "GPT.chat(\n",
    "    user_msg=\"Where can I get the latest information?\",\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
