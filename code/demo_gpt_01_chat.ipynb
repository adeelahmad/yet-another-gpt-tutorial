{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee5fb83",
   "metadata": {},
   "source": [
    "### How to chat with GPT using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0533bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[0.27.8]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from retrying import retry\n",
    "from IPython.display import Markdown,display\n",
    "print (\"openai version:[%s]\"%(openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "900baa7d",
   "metadata": {},
   "source": [
    "### Locate where your key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3b903b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = '../key/rilab_key.txt'\n",
    "print ('key_path:[%s]'%(key_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b49b03f",
   "metadata": {},
   "source": [
    "### Use key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc2fc79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(key_path, 'r') as f: OPENAI_API_KEY = f.read()\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd6db4",
   "metadata": {},
   "source": [
    "### Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "830439b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "@retry(stop_max_attempt_number=5,\n",
    "       wait_exponential_multiplier=1000,\n",
    "       wait_exponential_max=10000)\n",
    "def query_gpt(messages:list,gpt_model='gpt-4'):\n",
    "    \"\"\"\n",
    "        gpt_model: 'gpt-3.5-turbo' / 'gpt-4'\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API\n",
    "    response     = openai.ChatCompletion.create(\n",
    "        model    = gpt_model, \n",
    "        messages = messages\n",
    "    )\n",
    "    # Extract the response content and status code\n",
    "    content     = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    status_code = response[\"choices\"][0][\"finish_reason\"]\n",
    "    return content,status_code,response\n",
    "print (\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48f062",
   "metadata": {},
   "source": [
    "`messages`, an input to GPT, is basically a list where each item is a dictionary consists of `role` and `content`. A `role` can either be\n",
    "* `system`: which defines the identity of the agent\n",
    "* `user`: which states the input of a user\n",
    "* `assistant`: which stores messages previously generated by the agents\n",
    "More information can be found in [here](https://platform.openai.com/docs/guides/gpt/chat-completions-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84ab7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': '너는 한국어로 대화에 능통한 언어모델이야'}, {'role': 'user', 'content': 'LLM(Large Language Model)은 어떻게 작동하는지 설명해줘'}]\n"
     ]
    }
   ],
   "source": [
    "role_msg = \"\"\"너는 한국어로 대화에 능통한 언어모델이야\"\"\"\n",
    "question = \"LLM(Large Language Model)은 어떻게 작동하는지 설명해줘\"\n",
    "messages = [{\"role\": \"system\", \"content\": f'{role_msg}'},\n",
    "            {\"role\": 'user', \"content\": f'{question}'}]\n",
    "print (messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f4f53",
   "metadata": {},
   "source": [
    "### Now let's use `GPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccc1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "content,status_code,response = query_gpt(messages=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74676205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM(Large Language Model)은 인공지능이 텍스트를 이해하고 생성하는 능력을 가진 모델입니다. 그 중 가장 대표적인 것이 GPT-3 같은 트랜스포머 기반의 모델들이죠.\n",
      "\n",
      "이 모델들은 대량의 텍스트 데이터로 학습하는데요. 학습 과정에서는 문장이나 문단, 또는 웹페이지나 책 등 다양한 길이의 텍스트 조각들이 입력되며, 그 다음에 올 텍스트를 예측하도록 학습됩니다. \n",
      "\n",
      "트랜스포머 기반의 모델들은 인코더와 디코더 구조를 가지고 있어서, 인코더가 입력 텍스트를 내부적인 상태로 변환하고, 디코더가 그 상태를 다시 텍스트로 변환하는 데 사용됩니다. 그리고 이런 변환 과정에서 어떤 단어 또는 문구가 다음에 나타날 확률이 가장 높은지를 모델화합니다.\n",
      "\n",
      "모델이 이렇게 학습하면서 언어의 문법, 단어가 가진 의미, 문장 구조, 문맥 등 다양한 것들을 배우게 되는데, 이런 지식은 모델이 새로운 텍스트를 생성할 때 사용됩니다. 그리고 이것이 가능하게 하는 핵심 기술이 바로 딥러닝, 즉 깊은 신경망입니다.\n",
      "\n",
      "마지막으로, 아무리 훌륭한 모델이라도 제 제약사항과 한계가 있기 때문에, LLM은 사용자의 의도를 완벽하게 이해하거나, 거짓 정보를 구별하는 능력 등을 가질 수는 없습니다.\n"
     ]
    }
   ],
   "source": [
    "print (content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d330b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop\n"
     ]
    }
   ],
   "source": [
    "print (status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9daf9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-7alClH4rQIUrhnbj7qhQodHTTQqQ9\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1688995619,\n",
      "  \"model\": \"gpt-4-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"LLM(Large Language Model)\\uc740 \\uc778\\uacf5\\uc9c0\\ub2a5\\uc774 \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc774\\ud574\\ud558\\uace0 \\uc0dd\\uc131\\ud558\\ub294 \\ub2a5\\ub825\\uc744 \\uac00\\uc9c4 \\ubaa8\\ub378\\uc785\\ub2c8\\ub2e4. \\uadf8 \\uc911 \\uac00\\uc7a5 \\ub300\\ud45c\\uc801\\uc778 \\uac83\\uc774 GPT-3 \\uac19\\uc740 \\ud2b8\\ub79c\\uc2a4\\ud3ec\\uba38 \\uae30\\ubc18\\uc758 \\ubaa8\\ub378\\ub4e4\\uc774\\uc8e0.\\n\\n\\uc774 \\ubaa8\\ub378\\ub4e4\\uc740 \\ub300\\ub7c9\\uc758 \\ud14d\\uc2a4\\ud2b8 \\ub370\\uc774\\ud130\\ub85c \\ud559\\uc2b5\\ud558\\ub294\\ub370\\uc694. \\ud559\\uc2b5 \\uacfc\\uc815\\uc5d0\\uc11c\\ub294 \\ubb38\\uc7a5\\uc774\\ub098 \\ubb38\\ub2e8, \\ub610\\ub294 \\uc6f9\\ud398\\uc774\\uc9c0\\ub098 \\ucc45 \\ub4f1 \\ub2e4\\uc591\\ud55c \\uae38\\uc774\\uc758 \\ud14d\\uc2a4\\ud2b8 \\uc870\\uac01\\ub4e4\\uc774 \\uc785\\ub825\\ub418\\uba70, \\uadf8 \\ub2e4\\uc74c\\uc5d0 \\uc62c \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc608\\uce21\\ud558\\ub3c4\\ub85d \\ud559\\uc2b5\\ub429\\ub2c8\\ub2e4. \\n\\n\\ud2b8\\ub79c\\uc2a4\\ud3ec\\uba38 \\uae30\\ubc18\\uc758 \\ubaa8\\ub378\\ub4e4\\uc740 \\uc778\\ucf54\\ub354\\uc640 \\ub514\\ucf54\\ub354 \\uad6c\\uc870\\ub97c \\uac00\\uc9c0\\uace0 \\uc788\\uc5b4\\uc11c, \\uc778\\ucf54\\ub354\\uac00 \\uc785\\ub825 \\ud14d\\uc2a4\\ud2b8\\ub97c \\ub0b4\\ubd80\\uc801\\uc778 \\uc0c1\\ud0dc\\ub85c \\ubcc0\\ud658\\ud558\\uace0, \\ub514\\ucf54\\ub354\\uac00 \\uadf8 \\uc0c1\\ud0dc\\ub97c \\ub2e4\\uc2dc \\ud14d\\uc2a4\\ud2b8\\ub85c \\ubcc0\\ud658\\ud558\\ub294 \\ub370 \\uc0ac\\uc6a9\\ub429\\ub2c8\\ub2e4. \\uadf8\\ub9ac\\uace0 \\uc774\\ub7f0 \\ubcc0\\ud658 \\uacfc\\uc815\\uc5d0\\uc11c \\uc5b4\\ub5a4 \\ub2e8\\uc5b4 \\ub610\\ub294 \\ubb38\\uad6c\\uac00 \\ub2e4\\uc74c\\uc5d0 \\ub098\\ud0c0\\ub0a0 \\ud655\\ub960\\uc774 \\uac00\\uc7a5 \\ub192\\uc740\\uc9c0\\ub97c \\ubaa8\\ub378\\ud654\\ud569\\ub2c8\\ub2e4.\\n\\n\\ubaa8\\ub378\\uc774 \\uc774\\ub807\\uac8c \\ud559\\uc2b5\\ud558\\uba74\\uc11c \\uc5b8\\uc5b4\\uc758 \\ubb38\\ubc95, \\ub2e8\\uc5b4\\uac00 \\uac00\\uc9c4 \\uc758\\ubbf8, \\ubb38\\uc7a5 \\uad6c\\uc870, \\ubb38\\ub9e5 \\ub4f1 \\ub2e4\\uc591\\ud55c \\uac83\\ub4e4\\uc744 \\ubc30\\uc6b0\\uac8c \\ub418\\ub294\\ub370, \\uc774\\ub7f0 \\uc9c0\\uc2dd\\uc740 \\ubaa8\\ub378\\uc774 \\uc0c8\\ub85c\\uc6b4 \\ud14d\\uc2a4\\ud2b8\\ub97c \\uc0dd\\uc131\\ud560 \\ub54c \\uc0ac\\uc6a9\\ub429\\ub2c8\\ub2e4. \\uadf8\\ub9ac\\uace0 \\uc774\\uac83\\uc774 \\uac00\\ub2a5\\ud558\\uac8c \\ud558\\ub294 \\ud575\\uc2ec \\uae30\\uc220\\uc774 \\ubc14\\ub85c \\ub525\\ub7ec\\ub2dd, \\uc989 \\uae4a\\uc740 \\uc2e0\\uacbd\\ub9dd\\uc785\\ub2c8\\ub2e4.\\n\\n\\ub9c8\\uc9c0\\ub9c9\\uc73c\\ub85c, \\uc544\\ubb34\\ub9ac \\ud6cc\\ub96d\\ud55c \\ubaa8\\ub378\\uc774\\ub77c\\ub3c4 \\uc81c \\uc81c\\uc57d\\uc0ac\\ud56d\\uacfc \\ud55c\\uacc4\\uac00 \\uc788\\uae30 \\ub54c\\ubb38\\uc5d0, LLM\\uc740 \\uc0ac\\uc6a9\\uc790\\uc758 \\uc758\\ub3c4\\ub97c \\uc644\\ubcbd\\ud558\\uac8c \\uc774\\ud574\\ud558\\uac70\\ub098, \\uac70\\uc9d3 \\uc815\\ubcf4\\ub97c \\uad6c\\ubcc4\\ud558\\ub294 \\ub2a5\\ub825 \\ub4f1\\uc744 \\uac00\\uc9c8 \\uc218\\ub294 \\uc5c6\\uc2b5\\ub2c8\\ub2e4.\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 60,\n",
      "    \"completion_tokens\": 531,\n",
      "    \"total_tokens\": 591\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print (response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddce3",
   "metadata": {},
   "source": [
    "### Helper Class for implementing efficient chat with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46db1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "class GPTchatClass():\n",
    "    def __init__(self,\n",
    "                 gpt_model = 'gpt-4',\n",
    "                 role_msg  = 'Your are a helpful assistant.',\n",
    "                 VERBOSE   = True\n",
    "                ):\n",
    "        self.gpt_model     = gpt_model\n",
    "        self.messages      = [{'role':'system','content':f'{role_msg}'}]\n",
    "        self.init_messages = [{'role':'system','content':f'{role_msg}'}]\n",
    "        self.VERBOSE       = VERBOSE\n",
    "        self.response      = None\n",
    "        if self.VERBOSE:\n",
    "            print (\"Chat agent using [%s] initialized with the follow role:[%s]\"%\n",
    "                   (self.gpt_model,role_msg))\n",
    "    \n",
    "    def _add_message(self,role='assistant',content=''):\n",
    "        \"\"\"\n",
    "            role: 'assistant' / 'user'\n",
    "        \"\"\"\n",
    "        self.messages.append({'role':role, 'content':content})\n",
    "        \n",
    "    def _get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['content']\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def _get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response['choices'][0]['message']['finish_reason']\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def chat(self,user_msg='hi',\n",
    "             PRINT_USER_MSG=True,PRINT_GPT_OUTPUT=True,\n",
    "             RESET_CHAT=False,RETURN_RESPONSE=True):\n",
    "        self._add_message(role='user',content=user_msg)\n",
    "        self.response = openai.ChatCompletion.create(\n",
    "            model    = self.gpt_model,\n",
    "            messages = self.messages\n",
    "        )\n",
    "        # Backup response for continous chatting\n",
    "        self._add_message(role='assistant',content=self._get_response_content())\n",
    "        if PRINT_USER_MSG:\n",
    "            print(\"[USER_MSG]\")\n",
    "            printmd(user_msg)\n",
    "        if PRINT_GPT_OUTPUT:\n",
    "            print(\"[GPT_OUTPUT]\")\n",
    "            printmd(self._get_response_content())\n",
    "        # Reset\n",
    "        if RESET_CHAT:\n",
    "            self.messages = self.init_messages\n",
    "        # Return\n",
    "        if RETURN_RESPONSE:\n",
    "            return self._get_response_content()\n",
    "print (\"Ready.\")              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240f58b",
   "metadata": {},
   "source": [
    "### Now let's chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c6ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat agent using [gpt-4] initialized with the follow role:[Your are a helpful assistant.]\n",
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As of my last update, the current president of South Korea is Moon Jae-in. He has been in office since May 10, 2017. Please check the latest sources for the most recent information."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I'm sorry for any confusion. As of March 10, 2023, the President of South Korea is Yoon Suk-yeol."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "You can get the latest information about current world leaders from reliable news sources such as:\n",
       "\n",
       "1. International News Websites: Websites like BBC, CNN, or Al Jazeera regularly update their content to reflect recent changes in leadership.\n",
       "2. Official Government Websites: In this instance, the official government website of South Korea.\n",
       "3. Google News: Google News aggregates news from many different sources and is usually up-to-date.\n",
       "4. Social Media: Social media platforms like Twitter often have real-time updates for major world events. \n",
       "   \n",
       "Remember to ensure that the information source is reliable before taking it as fact."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model='gpt-4',role_msg  = 'Your are a helpful assistant.')\n",
    "PRINT_USER_MSG   = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT       = False\n",
    "RETURN_RESPONSE  = False\n",
    "GPT.chat(user_msg='Who is the current president of Korea?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Are you sure? I think you are outdated.',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Where can I get the latest information?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3dff58",
   "metadata": {},
   "source": [
    "### Chat with resetting everytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b3982d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat agent using [gpt-4] initialized with the follow role:[Your are a helpful assistant.]\n",
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Who is the current president of Korea?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The current president of South Korea, as of 2022, is Moon Jae-in. He has been in office since May 10, 2017. However, please verify from a up-to-date source, as this information might change over time."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Are you sure? I think you are outdated."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "As an AI, I'm always connected to the internet and periodically updated. My main goal is to help and provide the most efficient, updated information and assistance for any questions you have. How may I assist you further?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[USER_MSG]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Where can I get the latest information?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPT_OUTPUT]\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "The source of the latest information depends on the type of information you're looking for. Here are a few possibilities:\n",
       "\n",
       "1. News: Websites like CNN, BBC, and Al Jazeera, among others. They also have apps you can download on your phone.\n",
       "2. Technology: Websites like TechCrunch, CNET, Wired, or Gizmodo provide the latest tech news and updates.\n",
       "3. Academic: Websites like Google Scholar, JSTOR, and EBSCOhost have huge databases full of academic articles.\n",
       "4. Business/Finance: Websites like Bloomberg, Financial Times, and The Wall Street Journal are major sources for business and finance news.\n",
       "5. Entertainment: Websites like The Hollywood Reporter, Billboard, or IMDB have the latest in entertainment news.\n",
       "\n",
       "Please specify the area you're interested in for more detailed advice!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPTchatClass(gpt_model='gpt-4',role_msg  = 'Your are a helpful assistant.')\n",
    "PRINT_USER_MSG   = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT       = True\n",
    "RETURN_RESPONSE  = False\n",
    "GPT.chat(user_msg='Who is the current president of Korea?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Are you sure? I think you are outdated.',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)\n",
    "GPT.chat(user_msg='Where can I get the latest information?',\n",
    "         PRINT_USER_MSG=PRINT_USER_MSG,PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "         RESET_CHAT=RESET_CHAT,RETURN_RESPONSE=RETURN_RESPONSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b54979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
