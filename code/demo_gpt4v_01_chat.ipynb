{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fee5fb83",
   "metadata": {},
   "source": [
    "### How to chat with GPT using OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d0533bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "openai version:[1.3.7]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from rich.console import Console\n",
    "from typing import List, Dict, Optional\n",
    "\n",
    "print(\"openai version:[%s]\" % (openai.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5869e462",
   "metadata": {},
   "source": [
    "### Locate where your key is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3af4a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key_path:[../key/rilab_key.txt]\n"
     ]
    }
   ],
   "source": [
    "key_path = \"../key/rilab_key.txt\"\n",
    "print(\"key_path:[%s]\" % (key_path))\n",
    "\n",
    "with open(key_path, \"r\") as f:\n",
    "    OPENAI_API_KEY = f.read()\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd6db4",
   "metadata": {},
   "source": [
    "### Query function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "830439b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "def query_gpt(messages: List[Dict], gpt_model=\"gpt-4-vision-preview\"):\n",
    "    \"\"\"\n",
    "    gpt_model: 'gpt-4-vision-preview'\n",
    "    refer to : https://platform.openai.com/docs/guides/vision\n",
    "    \"\"\"\n",
    "    # Call the OpenAI API\n",
    "    response = client.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    # Extract the response content and status code\n",
    "    content = response.choices[0].message.content\n",
    "    status_code = response.choices[0].finish_reason\n",
    "    return content, status_code, response\n",
    "\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48f062",
   "metadata": {},
   "source": [
    "`messages`, an input to GPT, is basically a list where each item is a dictionary consists of `role` and `content`. A `role` can either be\n",
    "* `system`: which defines the identity of the agent\n",
    "* `user`: which states the input of a user\n",
    "* `assistant`: which stores messages previously generated by the agents\n",
    "More information can be found in [here](https://platform.openai.com/docs/guides/gpt/chat-completions-api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ab7761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': 'You are a helpful agent with vision capabilities; do not respond to objects not depicted in images.'}, {'role': 'user', 'content': [{'type': 'text', 'text': 'What’s in this image?'}, {'type': 'image_url', 'image_url': {'url': 'https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg'}}]}]\n"
     ]
    }
   ],
   "source": [
    "role_msg = \"\"\"You are a helpful agent with vision capabilities; do not respond to objects not depicted in images.\"\"\"\n",
    "question = \"What’s in this image?\"\n",
    "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"{role_msg}\"},\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "            {\"type\": \"text\", \"text\": \"What’s in this image?\"},\n",
    "            {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    },\n",
    "]\n",
    "\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7f4f53",
   "metadata": {},
   "source": [
    "### Now let's use `GPT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ccc1957",
   "metadata": {},
   "outputs": [],
   "source": [
    "content, status_code, response = query_gpt(messages=messages, gpt_model=\"gpt-4-vision-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74676205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image depicts a tranquil natural setting featuring a wooden boardwalk stretching out into the\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d330b693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9daf9aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8T4Z9LJ2nnajDUnnlVMkez2ensmM2', choices=[Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='The image depicts a tranquil natural setting featuring a wooden boardwalk stretching out into the', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'max_tokens'})], created=1701939755, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=16, prompt_tokens=1141, total_tokens=1157))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cddce3",
   "metadata": {},
   "source": [
    "### Helper Class for implementing efficient chat with GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46db1fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "import re\n",
    "import base64, io\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "\n",
    "\n",
    "class GPT4VchatClass:\n",
    "    def __init__(\n",
    "        self,\n",
    "        gpt_model: str = \"gpt-4-vision-preview\",\n",
    "        role_msg: str = \"You are a helpful agent with vision capabilities; do not respond to objects not depicted in images.\",\n",
    "        image_longaxis_max_size: int = 512,\n",
    "        VERBOSE: str = True,\n",
    "    ):\n",
    "        self.gpt_model = gpt_model\n",
    "        self.role_msg = role_msg\n",
    "        self.messages = [{\"role\": \"system\", \"content\": f\"{role_msg}\"}]\n",
    "        self.init_messages = [{\"role\": \"system\", \"content\": f\"{role_msg}\"}]\n",
    "        self.VERBOSE = VERBOSE\n",
    "        if self.VERBOSE:\n",
    "            self.console = Console()\n",
    "        self.response = None\n",
    "        self.image_longaxis_max_size = image_longaxis_max_size\n",
    "\n",
    "        self._setup_client()\n",
    "\n",
    "    def _setup_client(self, key_path: str = \"../\"):\n",
    "        key_path = \"../key/rilab_key.txt\"\n",
    "        if self.VERBOSE:\n",
    "            self.console.print(f\"[bold cyan]key_path:[%s][/bold cyan]\" % (key_path))\n",
    "\n",
    "        with open(key_path, \"r\") as f:\n",
    "            OPENAI_API_KEY = f.read()\n",
    "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "        if self.VERBOSE:\n",
    "            self.console.print(\n",
    "                \"[bold cyan]Chat agent using [%s] initialized with the follow role:[%s][/bold cyan]\"\n",
    "                % (self.gpt_model, self.role_msg)\n",
    "            )\n",
    "\n",
    "    def _encode_image(self, image_pil: Image.Image) -> str:\n",
    "        image_pil_rgb = image_pil.convert(\"RGB\")\n",
    "        # change pil to base64 string\n",
    "        img_buf = io.BytesIO()\n",
    "        image_pil_rgb.save(img_buf, format=\"PNG\")\n",
    "        # Encode bytes to base64 string\n",
    "        img_base64 = base64.b64encode(img_buf.getvalue()).decode(\"utf-8\")\n",
    "        return img_base64\n",
    "\n",
    "    def _divide_by_img_tag(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Example:\n",
    "        Input: \"<img1> <img2> What is the difference of these two images?\"\n",
    "        Output: ['<img1>', '<img2>', ' What is the difference of these two images?']\n",
    "        \"\"\"\n",
    "\n",
    "        pattern = r\"(<img\\d+>)\"\n",
    "        segments = re.split(pattern, text)\n",
    "        segments = [seg for seg in segments if seg.strip() != \"\"]\n",
    "\n",
    "        return segments\n",
    "\n",
    "    def _add_message(\n",
    "        self, role=\"assistant\", content: str = \"\", images: Optional[List] = None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        role: 'assistant' / 'user'\n",
    "        \"\"\"\n",
    "        if images is not None:\n",
    "            # parsing text content\n",
    "            image_text_segments = self._divide_by_img_tag(content)\n",
    "            new_content = []\n",
    "            image_num = 0\n",
    "            for segment in image_text_segments:\n",
    "                # check if image or text\n",
    "                if segment.startswith(\"<img\") and segment.endswith(\">\"):\n",
    "                    # this is image\n",
    "                    local_image_path = images[image_num]\n",
    "                    image_pil = Image.open(local_image_path)\n",
    "                    image_pil.thumbnail(\n",
    "                        (self.image_longaxis_max_size, self.image_longaxis_max_size)\n",
    "                    )\n",
    "                    base64_image = self._encode_image(image_pil)\n",
    "                    new_content.append(\n",
    "                        {\n",
    "                            \"type\": \"image_url\",\n",
    "                            \"image_url\": {\n",
    "                                \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "                            },\n",
    "                        }\n",
    "                    )\n",
    "                    image_num += 1\n",
    "\n",
    "                else:\n",
    "                    # this is text\n",
    "                    new_content.append(\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": segment,\n",
    "                        }\n",
    "                    )\n",
    "            self.messages.append({\"role\": role, \"content\": new_content})\n",
    "        else:\n",
    "            self.messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def _get_response_content(self):\n",
    "        if self.response:\n",
    "            return self.response.choices[0].message.content\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _get_response_status(self):\n",
    "        if self.response:\n",
    "            return self.response.choices[0].message.finish_reason\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def chat(\n",
    "        self,\n",
    "        user_msg: str = \"<img> what's in this image?\",\n",
    "        images: List[str] = [\"../img/cat.png\"],\n",
    "        PRINT_USER_MSG=True,\n",
    "        PRINT_GPT_OUTPUT=True,\n",
    "        RESET_CHAT=False,\n",
    "        RETURN_RESPONSE=True,\n",
    "        MAX_TOKENS = 512,\n",
    "    ):\n",
    "        self._add_message(role=\"user\", content=user_msg, images=images)\n",
    "        self.response = self.client.chat.completions.create(\n",
    "            model=self.gpt_model, messages=self.messages, max_tokens=MAX_TOKENS\n",
    "        )\n",
    "        print(self.response)\n",
    "        # Backup response for continous chatting\n",
    "        self._add_message(role=\"assistant\", content=self._get_response_content())\n",
    "        if PRINT_USER_MSG:\n",
    "            self.console.print(\"[deep_sky_blue3][USER_MSG][/deep_sky_blue3]\")\n",
    "            printmd(user_msg)\n",
    "        if PRINT_GPT_OUTPUT:\n",
    "            self.console.print(\"[spring_green4][GPT_OUTPUT][/spring_green4]\")\n",
    "            printmd(self._get_response_content())\n",
    "        # Reset\n",
    "        if RESET_CHAT:\n",
    "            self.messages = self.init_messages\n",
    "        # Return\n",
    "        if RETURN_RESPONSE:\n",
    "            return self._get_response_content()\n",
    "\n",
    "\n",
    "print(\"Ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c240f58b",
   "metadata": {},
   "source": [
    "### Now let's chat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918265e2",
   "metadata": {},
   "source": [
    "<img src=\"../img/cat.png\" width=\"256\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c6ad0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">key_path:[../key/rilab_key.txt]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mkey_path:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m..\u001b[0m\u001b[1;36m/key/\u001b[0m\u001b[1;36mrilab_key.txt\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Chat agent using  initialized with the follow role:[You are a helpful agent with vision capabilities; do not </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">respond to objects not depicted in images.]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mChat agent using \u001b[0m\u001b[1;36m initialized with the follow role:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36mYou are a helpful agent with vision capabilities; do not \u001b[0m\n",
       "\u001b[1;36mrespond to objects not depicted in images.\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8T4ZdC1vLXPgHJ31gLQIrEEFVWnmq', choices=[Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content=\"The image shows an adorable kitten standing on its hind legs with one front paw raised as if it is reaching for something above. The kitten has a fluffy coat with a combination of light brown, cream, and white colors and distinctive tabby markings on its face, along with a white chin and chest. It has large, round, and expressive eyes and appears curious or playful. The backdrop is a soft blue color, providing a calm and complimentary background that contrasts nicely with the kitten's warm tones.\", role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})], created=1701939785, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=99, prompt_tokens=289, total_tokens=388))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<img1> Describe the image."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The image shows an adorable kitten standing on its hind legs with one front paw raised as if it is reaching for something above. The kitten has a fluffy coat with a combination of light brown, cream, and white colors and distinctive tabby markings on its face, along with a white chin and chest. It has large, round, and expressive eyes and appears curious or playful. The backdrop is a soft blue color, providing a calm and complimentary background that contrasts nicely with the kitten's warm tones."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPT4VchatClass(\n",
    "    gpt_model=\"gpt-4-vision-preview\",\n",
    "    role_msg=\"You are a helpful agent with vision capabilities; do not respond to objects not depicted in images.\",\n",
    ")\n",
    "PRINT_USER_MSG = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT = False\n",
    "RETURN_RESPONSE = False\n",
    "GPT.chat(\n",
    "    user_msg=\"<img1> Describe the image.\",\n",
    "    images=[\"../img/cat.png\"],\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    "    MAX_TOKENS = 256,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3dff58",
   "metadata": {},
   "source": [
    "### Multi Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1142be5",
   "metadata": {},
   "source": [
    "<img src=\"../img/cat.png\" height=\"256\"> <img src=\"../img/dog.png\" height=\"256\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3982d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">key_path:[../key/rilab_key.txt]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mkey_path:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36m..\u001b[0m\u001b[1;36m/key/\u001b[0m\u001b[1;36mrilab_key.txt\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Chat agent using  initialized with the follow role:[You are a helpful agent with vision capabilities; do not </span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">respond to objects not depicted in images.]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mChat agent using \u001b[0m\u001b[1;36m initialized with the follow role:\u001b[0m\u001b[1;36m[\u001b[0m\u001b[1;36mYou are a helpful agent with vision capabilities; do not \u001b[0m\n",
       "\u001b[1;36mrespond to objects not depicted in images.\u001b[0m\u001b[1;36m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-8T4dk5RTf7AItnoA64MEquviWtv2F', choices=[Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='The first image features a cat, while the second image depicts a dog. The cat appears to be indoors with a solid light-colored background and is reaching upwards with its front paw, giving it a playful or curious expression. The dog, on the other hand, is outdoors, possibly on a beach, judging by the sandy ground, with a natural, bright sky background. The dog is seated and looking upward with a calm or inquisitive expression.\\n\\nIn summary, the differences include the species (cat vs. dog), the setting (indoor vs. outdoor), and the pose and expressions of the animals.', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})], created=1701940040, model='gpt-4-1106-vision-preview', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=122, prompt_tokens=548, total_tokens=670))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">[</span><span style=\"color: #0087d7; text-decoration-color: #0087d7\">USER_MSG</span><span style=\"color: #0087d7; text-decoration-color: #0087d7; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;32m[\u001b[0m\u001b[38;5;32mUSER_MSG\u001b[0m\u001b[1;38;5;32m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<img1> <img2> What is the difference between two images?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">[</span><span style=\"color: #00875f; text-decoration-color: #00875f\">GPT_OUTPUT</span><span style=\"color: #00875f; text-decoration-color: #00875f; font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;38;5;29m[\u001b[0m\u001b[38;5;29mGPT_OUTPUT\u001b[0m\u001b[1;38;5;29m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "The first image features a cat, while the second image depicts a dog. The cat appears to be indoors with a solid light-colored background and is reaching upwards with its front paw, giving it a playful or curious expression. The dog, on the other hand, is outdoors, possibly on a beach, judging by the sandy ground, with a natural, bright sky background. The dog is seated and looking upward with a calm or inquisitive expression.\n",
       "\n",
       "In summary, the differences include the species (cat vs. dog), the setting (indoor vs. outdoor), and the pose and expressions of the animals."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "GPT = GPT4VchatClass(\n",
    "    gpt_model=\"gpt-4-vision-preview\",\n",
    "    role_msg=\"You are a helpful agent with vision capabilities; do not respond to objects not depicted in images.\",\n",
    ")\n",
    "PRINT_USER_MSG = True\n",
    "PRINT_GPT_OUTPUT = True\n",
    "RESET_CHAT = True\n",
    "RETURN_RESPONSE = False\n",
    "GPT.chat(\n",
    "    user_msg=\"<img1> <img2> What is the difference between two images?\",\n",
    "    images=[\"../img/cat.png\", \"../img/dog.png\"],\n",
    "    PRINT_USER_MSG=PRINT_USER_MSG,\n",
    "    PRINT_GPT_OUTPUT=PRINT_GPT_OUTPUT,\n",
    "    RESET_CHAT=RESET_CHAT,\n",
    "    RETURN_RESPONSE=RETURN_RESPONSE,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
